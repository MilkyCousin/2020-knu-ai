{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "task-28_29-01-2020.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdMLlISca-7",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGCVJ8F4ca-9",
        "colab_type": "text"
      },
      "source": [
        "torch==1.1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G5rJl2zca--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "12664f5c-4710-4106-bd80-c22bc1489361"
      },
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch \n",
        "import torch.nn as nn \n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from string import punctuation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2zFflUfca_B",
        "colab_type": "code",
        "outputId": "93673929-7c57-47e6-aae3-b885642796d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/My Drive/train.csv\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAHKEG5Uca_D",
        "colab_type": "code",
        "outputId": "f0aa6e18-76bc-40fc-f695-6690affe5bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVzcnNEuca_G",
        "colab_type": "text"
      },
      "source": [
        "In this notebook you will learn pytorch basics, this framework will help you to build simple neural networks during this task.   \n",
        "The first neural network we will try to learn is Feed Forward Neural Network which contain one Fully Connected Layer.  \n",
        "It can have 1 or more fully connected layers, also it could be called as MLP - multilayer perceptron. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugDcW9xBca_H",
        "colab_type": "text"
      },
      "source": [
        "Read about PyTorch here:  \n",
        "https://en.wikipedia.org/wiki/PyTorch\n",
        "\n",
        "And here:\n",
        "\n",
        "https://neurohive.io/ru/tutorial/glubokoe-obuchenie-s-pytorch/\n",
        "\n",
        "While reading these articles probably you will meet some unknown terms: \n",
        "backpropagation algorithm, gradient descent, activation function, loss function, etc.  \n",
        "Please, try to look for an information about why do you need all of these stuff. \n",
        "\n",
        "Answer this questions about Neural Nets: \n",
        "\n",
        "1. In previous tasks we created some features manually, tried to weight our features, tried to select special words for vectorization, how deep learning solves this problem? \n",
        "\n",
        "2. Why do we work with tensors in PyTorch?\n",
        "\n",
        "3. Please, find and read information - why do we need an activation functions in our models? Please, refer to the XOR problem with MLP without activation function, find information about it and answer the previous question. \n",
        "\n",
        "4. Please, answer the following question - what gradient is? Why do we need gradient descent algorithm? Which problem it solves? \n",
        "\n",
        "5. What is backpropagation algorithm? \n",
        "\n",
        "6. What is loss function? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKHXEMAXD3qP",
        "colab_type": "text"
      },
      "source": [
        "1.Neural net creating features by itself. \n",
        "\n",
        "2.It's faster and more coveinient in context of Neural Networks.\n",
        "\n",
        "3.We need activation functions to add non-linearity in NN. Without activation function we can't learn ever XOR, beacuse it's linearly inseparable. \n",
        "\n",
        "4.Gradient - vector of partial derivatives of a function. Gradiant descent is an optimization algorithm. We need it to find minimum of loss function.\n",
        "\n",
        "5.Backprop is a rule how to update derivatives in gradient descent. \n",
        "\n",
        "6.Function which we are trying to minimize while training NN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQg4u-tTca_U",
        "colab_type": "text"
      },
      "source": [
        "Read the following article:\n",
        "\n",
        "https://en.wikipedia.org/wiki/Feedforward_neural_network\n",
        "\n",
        "What is FFNN? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BacXwFBPLKrH",
        "colab_type": "text"
      },
      "source": [
        "NN without recurrent layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC1QcVDaca_X",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urA_a2ruca_Y",
        "colab_type": "text"
      },
      "source": [
        "#### Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v71Cgjccca_a",
        "colab_type": "code",
        "outputId": "f8712a41-6ae4-44eb-8824-b80147551544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating a tensor:\n",
        "x = torch.ones(1, requires_grad=True)\n",
        "\n",
        "print(x.grad)    # returns None"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3aYXpe4ca_b",
        "colab_type": "text"
      },
      "source": [
        "print(x.grad) is None because a tensor x is a scalar, so there is nothing to be calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yYC2qCGca_c",
        "colab_type": "code",
        "outputId": "1c098baf-700a-43d0-a262-4c5ec5042ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.ones(1, requires_grad=True)\n",
        "y = 20 + x\n",
        "z = (y ** 2) * 2 \n",
        "z.backward()     # auto gradient calculation\n",
        "\n",
        "print(x.grad)    # ∂z/∂x "
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([84.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfSwLIF5ca_e",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cdQ7R6dca_f",
        "colab_type": "code",
        "outputId": "0654af14-76a0-4a37-fb2e-aeb450742454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrNoW8RyVxK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(tokenizer, lemmatizer, stop_words, punctuation, text): \n",
        "    tokens = tokenizer(text.lower())\n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return [token for token in lemmas if token not in stop_words and token not in punctuation and len(token) > 4 and len(token) < 20]\n",
        "\n",
        "df['cleaned'] = df.comment_text.apply(lambda x: preprocess_text(word_tokenize, lemmatizer, stop_words, punctuation, x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md9CgJw1ca_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modify labels dtype to 'int', to make summarizing them possible\n",
        "for column in df.columns: \n",
        "    if column not in ['id', 'comment_text', 'cleaned']:\n",
        "        df[column] = df[column].astype('int32')\n",
        "        \n",
        "# Create a toxicity column (sums all of the toxic labels)\n",
        "df['toxicity'] = df.iloc[:,2:8].sum(axis=1)\n",
        "\n",
        "# Clean data - where toxicity is == 0 \n",
        "clean = df[df['toxicity'] == 0]\n",
        "# Messages, which were labelled as obscene\n",
        "obscene = df[df['obscene'] == 1]\n",
        "\n",
        "# Create a dataset for binary classification \n",
        "df_binary = clean.append(obscene, ignore_index=True, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3TJwTdmca_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle\n",
        "df_binary = df_binary.sample(frac=1)\n",
        "\n",
        "# Reset index of the pd.DataFrame\n",
        "df_binary.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf7oGAgTca_k",
        "colab_type": "code",
        "outputId": "f6de8421-1444-49ec-b06b-f5616cd86940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_binary.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4889</td>\n",
              "      <td>0e9009250597b838</td>\n",
              "      <td>It's a temporary measure;  it's been there les...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[temporary, measure, every, wikipedia, result,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29161</td>\n",
              "      <td>5690a74218be68d3</td>\n",
              "      <td>\"\\n\\nI, for one, wish there had been discussio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[discussion, prior, relegating, article, coupl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5741</td>\n",
              "      <td>11299cd34577b931</td>\n",
              "      <td>Please feel free to ignore this warning, addin...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[please, ignore, warning, adding, source, arti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>149900</td>\n",
              "      <td>93e24c1fec3135d3</td>\n",
              "      <td>Why do you keep blocking me? \\n\\nYou are a big...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[blocking, idiot, dmacks, block, change, negot...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>111552</td>\n",
              "      <td>9865b015628af9cc</td>\n",
              "      <td>The current Signpost suggests we will be seein...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[current, signpost, suggests, seeing, sooner, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ... toxicity\n",
              "0    4889  ...        0\n",
              "1   29161  ...        0\n",
              "2    5741  ...        0\n",
              "3  149900  ...        3\n",
              "4  111552  ...        0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXKuvU5_ca_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b230b238-6ba6-4f8e-b0fd-2453d76e8f65"
      },
      "source": [
        "# Load W2V model \n",
        "\n",
        "we_model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vvMRpubca_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make stratified sampling, for example: select 500 examples with obscene == 1, and 500 clean examples. \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Select only a small sample of your data (20%), do not train your model on all of the data available \n",
        "# But to make the task easier, make a stratified selection \n",
        "# (number of 1 labels would be approximately equal to number of 0 labels)\n",
        "df_sample = df_binary.sample(20000)\n",
        "\n",
        "# Split the data on the stratified training and test data sets \n",
        "df_train, df_test = train_test_split(df_sample, test_size = 0.3, stratify = df_sample.toxic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6krekddca_q",
        "colab_type": "code",
        "outputId": "174bd5ac-479b-4b94-b6b6-c139cf2753d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Train shape: {}\".format(df_train.shape))\n",
        "print(\"Test shape: {}\".format(df_test.shape))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (14000, 11)\n",
            "Test shape: (6000, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa3h7TxFca_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vectors(df_sample): \n",
        "    '''\n",
        "    This function would process a DataFrame creating lists of:\n",
        "        vectors, labels and documents corresponding to each raw document. \n",
        "        \n",
        "    Args: \n",
        "        df: pd.DataFrame - DF to vectorize\n",
        "    Returns: \n",
        "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
        "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
        "        documents: list - List of the raw texts of the vectorized documents \n",
        "    '''\n",
        "    \n",
        "    # Obtain vectors for documents, vectorized documents list and labels\n",
        "    X, labels, documents = [], [], []\n",
        "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.toxic)):\n",
        "        row_vectors = []\n",
        "        for kw in tokens:\n",
        "            try: \n",
        "                row_vectors.append(we_model[kw])\n",
        "            except (IndexError, KeyError): \n",
        "                continue\n",
        "        if not row_vectors:\n",
        "            continue\n",
        "        row_vectors = np.asarray(row_vectors)\n",
        "        vec = row_vectors.mean(axis=0)\n",
        "        X.append(torch.tensor(vec))\n",
        "        documents.append(document)\n",
        "        labels.append(torch.tensor(label, dtype=torch.float))\n",
        "        \n",
        "    return X, labels, documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu5bC-_Tca_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train, documents_train = get_vectors(df_train)\n",
        "X_test, y_test, documents_test = get_vectors(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7qL3m5mca_v",
        "colab_type": "text"
      },
      "source": [
        "### How to create a simple NN: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGio92Rpca_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modify your model to work with batches, not only single item. \n",
        "''' TASK HERE'''\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size  = hidden_size\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.logits = nn.Linear(self.hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Makes a forward pass \n",
        "        hidden = self.fc1(x)\n",
        "        relu = self.relu(hidden)\n",
        "        logits = self.logits(relu)\n",
        "        output = self.sigmoid(logits)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu5-j2kuca_x",
        "colab_type": "code",
        "outputId": "b8cf6e4f-bf64-4f21-d968-dd6994c8729d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Initialise the model \n",
        "model = FeedForward(300, 200)\n",
        "\n",
        "# Specify loss and optimization functions:\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.BCELoss()\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "# Move model to the training mode\n",
        "model.train()\n",
        "\n",
        "# init n_epochs \n",
        "n_epochs = 10\n",
        "\n",
        "# init number of iterations for one epoch \n",
        "# we want our model during the epoch to walk trough all of the training examples \n",
        "# for batch_size == 1, number of iterations would be equal to number of examples \n",
        "# in the training set \n",
        "n_iters = len(X_train)\n",
        "\n",
        "# initialise batch_size\n",
        "# NOTE! for now it's equal == 1, you need to modify your model to make it possible to work with \n",
        "# batches during training, not only making an update for a single example \n",
        "batch_size = 1\n",
        "for epoch in range(n_epochs):  \n",
        "    epoch_loss = 0\n",
        "    for idx in range(n_iters):\n",
        "        \n",
        "        # Selects only 1 sample, modify it to select N samples, N == batch_size\n",
        "        ''' TASK HERE'''\n",
        "        # idx = random.sample(range(len(X_train)), 1) # TIP: You can random sample N examples \n",
        "        \n",
        "        optimizer.zero_grad()    # Forward pass\n",
        "\n",
        "        # Select corresponding data from:\n",
        "        # X (vectors) and labels - for calculating the loss and making a backward pass \n",
        "        # backward pass - updating our weights according to the obtained loss \n",
        "        ''' TASK HERE'''\n",
        "        x = X_train[idx]\n",
        "        y_true = y_train[idx]\n",
        "\n",
        "        y_pred = model(x)    # Compute Loss\n",
        "        loss = criterion(y_pred.squeeze(), y_true)\n",
        "        \n",
        "        epoch_loss += loss.item() / n_iters\n",
        "        loss.backward()   # Backward pass \n",
        "        optimizer.step()\n",
        "        \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))    # Backward pass"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 0.16041085071335473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-804f90dcfbb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Compute Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-8bacfe704c9f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERlJiedwca_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictions(model, X_test, y_test, documents_test, threshold): \n",
        "    n_prints = 0\n",
        "    preds = []\n",
        "    for example, label, document in zip(X_test, y_test, documents_test):\n",
        "        pred = model(example)\n",
        "        y_pred = int(pred.item() > threshold)\n",
        "        preds.append(y_pred)\n",
        "        \n",
        "        # Print some examples with obscene documents texts and predicted and true labels \n",
        "        if label.item() == 1.0 and n_prints < 10:\n",
        "            print(\"Predicted label: {}\".format(y_pred))\n",
        "            print(\"True label: {}\".format(label.item()))\n",
        "            print(\"Document: {}\".format(document))\n",
        "            print(\"*-*-\"*20)\n",
        "            n_prints += 1\n",
        "        \n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1PeNWY1ca_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move model to the eval mode before making a prediction\n",
        "model.eval()\n",
        "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
        "\n",
        "test_labels = [label.item() for label in y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XEzPUf9qca_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pring a classification report: \n",
        "print(classification_report(test_labels, preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDNv-_6wca_4",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: \n",
        "\n",
        "#### Find all of the ''' TASK HERE ''' messages. \n",
        "\n",
        "1. Create stratified dataset, make your classes balanced! Train the model. Try to beat the initial score.\n",
        "\n",
        "2. While vectorizing by W2V model, add tf-idf weightning, look at TfidfVectorizer at sklearn. \n",
        "\n",
        "3. Add batch size, modify your model architecture to make it possible to process batches, not only single items. \n",
        "\n",
        "4. Change hidden_size, n_layers, activation function, etc to modify your model. \n",
        "\n",
        "5. Tweak learning rate, see what happened if LR is too small, if too big (0.0001 / 0.8 for example)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQaBdvUOca_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tip:\n",
        "# Use tf-idf scores calculated by sklearn:\n",
        "\n",
        "def dummy_fun(doc):\n",
        "    # This function is used to replace a default tokenizer in sklearn. \n",
        "    # If you are passing a tokenized documents to the tf-idf vectorizer - \n",
        "    # it would be much faster \n",
        "    return doc\n",
        "\n",
        "def make_predictions(model, X_test, threshold=0.5): \n",
        "    preds = []\n",
        "    for example in X_test:\n",
        "        pred = model(example)\n",
        "        y_pred = int(pred.item() > threshold)\n",
        "        preds.append(y_pred)\n",
        "\n",
        "    return preds\n",
        "\n",
        "def get_idf(tokenized_docs, max_features=180000):\n",
        "    ''' Returns a tf-idf dictionary: \n",
        "            key: word,\n",
        "            value: tf-idf score. \n",
        "    '''\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        min_df=3,\n",
        "        max_features=max_features,\n",
        "        analyzer='word',\n",
        "        tokenizer=dummy_fun,\n",
        "        preprocessor=dummy_fun,\n",
        "        token_pattern=None,\n",
        "        ngram_range=(1, 1))\n",
        "\n",
        "    vectorizer.fit(tokenized_docs)\n",
        "    idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
        "    \n",
        "    return idf_dict\n",
        "\n",
        "def get_weighted_vectors(df_sample): \n",
        "    '''\n",
        "    This function would process a DataFrame creating lists of:\n",
        "        vectors, labels and documents corresponding to each raw document. \n",
        "        \n",
        "    Args: \n",
        "        df: pd.DataFrame - DF to vectorize\n",
        "    Returns: \n",
        "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
        "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
        "        documents: list - List of the raw texts of the vectorized documents \n",
        "    '''\n",
        "    \n",
        "    tfidf_dict = get_idf(df_sample.cleaned)\n",
        "    # Obtain vectors for documents, vectorized documents list and labels\n",
        "    X, labels, documents = [], [], []\n",
        "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.toxic)):\n",
        "        row_vectors = []\n",
        "        for kw in tokens:\n",
        "            try: \n",
        "                row_vectors.append(we_model[kw]*tfidf_dict[kw])\n",
        "            except (IndexError, KeyError): \n",
        "                continue\n",
        "        if not row_vectors:\n",
        "            continue\n",
        "        row_vectors = np.asarray(row_vectors)\n",
        "        vec = row_vectors.mean(axis=0)\n",
        "        X.append(torch.tensor(vec))\n",
        "        documents.append(document)\n",
        "        labels.append(torch.tensor(label, dtype=torch.float))\n",
        "        \n",
        "    return X, labels, documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC5b3P-a3dSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample = df_binary.sample(100000)\n",
        "df_train, df_test = train_test_split(df_sample, test_size = 0.3, stratify = df_sample.toxic)\n",
        "\n",
        "X_train, y_train, documents_train = get_weighted_vectors(df_train)\n",
        "X_test, y_test, documents_test = get_weighted_vectors(df_test)\n",
        "\n",
        "X_train = torch.stack(X_train)\n",
        "y_train = torch.stack(y_train)\n",
        "\n",
        "X_test = torch.stack(X_test)\n",
        "y_test = torch.stack(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ix5T6Msl7sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size_1, hidden_size_1, hidden_size_2):\n",
        "        super().__init__()\n",
        "        self.input_size_1 = input_size_1\n",
        "        self.hidden_size_1 = hidden_size_1\n",
        "        self.hidden_size_2 = hidden_size_2\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.input_size_1, self.hidden_size_1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(self.hidden_size_1, self.hidden_size_2)\n",
        "        self.logits = nn.Linear(self.hidden_size_2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        hidden_1 = self.fc1(x)\n",
        "        relu = self.relu(hidden_1)\n",
        "        hidden_2 = self.fc2(relu)\n",
        "        relu = self.relu(hidden_2)\n",
        "        logits = self.logits(relu)\n",
        "        output = self.sigmoid(logits)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liu8W_Rno2ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37781dbd-28d0-415d-f09b-004d82e17bae"
      },
      "source": [
        "model = FeedForward(300, 300, 150)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)\n",
        "model.train()\n",
        "n_epochs = 120\n",
        "n_iters = 100\n",
        "batch_size = len(X_train) // n_iters\n",
        "\n",
        "for epoch in range(n_epochs):  \n",
        "    epoch_loss = 0\n",
        "    for idx in range(n_iters):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        idx = random.sample(range(len(X_train)), batch_size)\n",
        "\n",
        "        x = X_train[idx]\n",
        "        y_true = y_train[idx]\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred.squeeze(), y_true)\n",
        "        epoch_loss += loss.item() / n_iters\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch {}: train loss: {};'.format(epoch, epoch_loss))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds_train = preds_test = make_predictions(model, X_train)\n",
        "preds_test = make_predictions(model, X_test)\n",
        "\n",
        "train_labels = [label.item() for label in y_train]\n",
        "test_labels = [label.item() for label in y_test]\n",
        "\n",
        "\n",
        "print(classification_report(train_labels, preds_train))\n",
        "print(classification_report(test_labels, preds_test))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 0.6211396008729934;\n",
            "Epoch 1: train loss: 0.5746709966659546;\n",
            "Epoch 2: train loss: 0.5313718396425247;\n",
            "Epoch 3: train loss: 0.4879178181290627;\n",
            "Epoch 4: train loss: 0.4476482385396957;\n",
            "Epoch 5: train loss: 0.41142268151044836;\n",
            "Epoch 6: train loss: 0.377664329111576;\n",
            "Epoch 7: train loss: 0.34304334461688996;\n",
            "Epoch 8: train loss: 0.31692695081233985;\n",
            "Epoch 9: train loss: 0.2937179663777353;\n",
            "Epoch 10: train loss: 0.27289988532662396;\n",
            "Epoch 11: train loss: 0.2615836913883685;\n",
            "Epoch 12: train loss: 0.24828577265143412;\n",
            "Epoch 13: train loss: 0.238779913932085;\n",
            "Epoch 14: train loss: 0.2307542480528354;\n",
            "Epoch 15: train loss: 0.2225910311937331;\n",
            "Epoch 16: train loss: 0.22129348337650295;\n",
            "Epoch 17: train loss: 0.21392185091972352;\n",
            "Epoch 18: train loss: 0.2108626137673854;\n",
            "Epoch 19: train loss: 0.2098289927840232;\n",
            "Epoch 20: train loss: 0.20392102241516105;\n",
            "Epoch 21: train loss: 0.19967376783490176;\n",
            "Epoch 22: train loss: 0.19969317376613616;\n",
            "Epoch 23: train loss: 0.19922337904572487;\n",
            "Epoch 24: train loss: 0.19528861850500115;\n",
            "Epoch 25: train loss: 0.1949923551082611;\n",
            "Epoch 26: train loss: 0.19263540223240852;\n",
            "Epoch 27: train loss: 0.18973562687635415;\n",
            "Epoch 28: train loss: 0.18989804342389108;\n",
            "Epoch 29: train loss: 0.18990133389830588;\n",
            "Epoch 30: train loss: 0.18652300700545313;\n",
            "Epoch 31: train loss: 0.18750410526990896;\n",
            "Epoch 32: train loss: 0.17955335900187486;\n",
            "Epoch 33: train loss: 0.1813360096514225;\n",
            "Epoch 34: train loss: 0.17721983872354025;\n",
            "Epoch 35: train loss: 0.17633343458175654;\n",
            "Epoch 36: train loss: 0.1757372392714023;\n",
            "Epoch 37: train loss: 0.1754971696436405;\n",
            "Epoch 38: train loss: 0.17562242552638052;\n",
            "Epoch 39: train loss: 0.17128244988620278;\n",
            "Epoch 40: train loss: 0.16799637526273725;\n",
            "Epoch 41: train loss: 0.16772854588925837;\n",
            "Epoch 42: train loss: 0.16579916611313825;\n",
            "Epoch 43: train loss: 0.17035704106092453;\n",
            "Epoch 44: train loss: 0.16502813063561922;\n",
            "Epoch 45: train loss: 0.16308698132634158;\n",
            "Epoch 46: train loss: 0.16243663199245928;\n",
            "Epoch 47: train loss: 0.1626127065718173;\n",
            "Epoch 48: train loss: 0.1627256771177054;\n",
            "Epoch 49: train loss: 0.1578347762674093;\n",
            "Epoch 50: train loss: 0.16050894044339653;\n",
            "Epoch 51: train loss: 0.15714043304324163;\n",
            "Epoch 52: train loss: 0.15527555190026762;\n",
            "Epoch 53: train loss: 0.15835105411708356;\n",
            "Epoch 54: train loss: 0.1559735995531082;\n",
            "Epoch 55: train loss: 0.15423169061541567;\n",
            "Epoch 56: train loss: 0.1508279837667942;\n",
            "Epoch 57: train loss: 0.1502950492501259;\n",
            "Epoch 58: train loss: 0.15015915028750898;\n",
            "Epoch 59: train loss: 0.1502761612087489;\n",
            "Epoch 60: train loss: 0.1460249281674622;\n",
            "Epoch 61: train loss: 0.1470410882681608;\n",
            "Epoch 62: train loss: 0.1473203275352716;\n",
            "Epoch 63: train loss: 0.14751328207552436;\n",
            "Epoch 64: train loss: 0.1468075427412987;\n",
            "Epoch 65: train loss: 0.14502305679023264;\n",
            "Epoch 66: train loss: 0.14595214895904063;\n",
            "Epoch 67: train loss: 0.1430037035048008;\n",
            "Epoch 68: train loss: 0.14349301569163794;\n",
            "Epoch 69: train loss: 0.14428910695016386;\n",
            "Epoch 70: train loss: 0.14222279034554955;\n",
            "Epoch 71: train loss: 0.14168760873377315;\n",
            "Epoch 72: train loss: 0.14042723447084426;\n",
            "Epoch 73: train loss: 0.14020099364221095;\n",
            "Epoch 74: train loss: 0.14027051351964478;\n",
            "Epoch 75: train loss: 0.13771477155387402;\n",
            "Epoch 76: train loss: 0.13907471865415574;\n",
            "Epoch 77: train loss: 0.13996556967496876;\n",
            "Epoch 78: train loss: 0.13808246813714506;\n",
            "Epoch 79: train loss: 0.13458877980709083;\n",
            "Epoch 80: train loss: 0.13309987530112263;\n",
            "Epoch 81: train loss: 0.13736397571861753;\n",
            "Epoch 82: train loss: 0.1349877148866653;\n",
            "Epoch 83: train loss: 0.1359491033852101;\n",
            "Epoch 84: train loss: 0.13373082712292672;\n",
            "Epoch 85: train loss: 0.1338364213705063;\n",
            "Epoch 86: train loss: 0.13471726737916473;\n",
            "Epoch 87: train loss: 0.13372567571699615;\n",
            "Epoch 88: train loss: 0.1321841656416655;\n",
            "Epoch 89: train loss: 0.13175318606197836;\n",
            "Epoch 90: train loss: 0.13346183806657785;\n",
            "Epoch 91: train loss: 0.13222682490944865;\n",
            "Epoch 92: train loss: 0.1299263143539429;\n",
            "Epoch 93: train loss: 0.12895477391779425;\n",
            "Epoch 94: train loss: 0.12775968298316007;\n",
            "Epoch 95: train loss: 0.12775776103138922;\n",
            "Epoch 96: train loss: 0.12838108755648137;\n",
            "Epoch 97: train loss: 0.12483339048922064;\n",
            "Epoch 98: train loss: 0.1312509836256504;\n",
            "Epoch 99: train loss: 0.12850906260311604;\n",
            "Epoch 100: train loss: 0.12688940249383449;\n",
            "Epoch 101: train loss: 0.12804612249135974;\n",
            "Epoch 102: train loss: 0.12827847734093664;\n",
            "Epoch 103: train loss: 0.12617190279066567;\n",
            "Epoch 104: train loss: 0.12940581522881983;\n",
            "Epoch 105: train loss: 0.12696977496147155;\n",
            "Epoch 106: train loss: 0.12610138393938541;\n",
            "Epoch 107: train loss: 0.12428705960512162;\n",
            "Epoch 108: train loss: 0.12404819898307325;\n",
            "Epoch 109: train loss: 0.12555279143154618;\n",
            "Epoch 110: train loss: 0.12279755935072897;\n",
            "Epoch 111: train loss: 0.12401662118732928;\n",
            "Epoch 112: train loss: 0.12229079589247713;\n",
            "Epoch 113: train loss: 0.12582281552255156;\n",
            "Epoch 114: train loss: 0.12412697970867159;\n",
            "Epoch 115: train loss: 0.12398028656840324;\n",
            "Epoch 116: train loss: 0.11962118849158286;\n",
            "Epoch 117: train loss: 0.12074580490589142;\n",
            "Epoch 118: train loss: 0.12285743623971937;\n",
            "Epoch 119: train loss: 0.12404620230197906;\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98     65178\n",
            "         1.0       0.93      0.20      0.34      3368\n",
            "\n",
            "    accuracy                           0.96     68546\n",
            "   macro avg       0.95      0.60      0.66     68546\n",
            "weighted avg       0.96      0.96      0.95     68546\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98     27931\n",
            "         1.0       0.94      0.21      0.34      1426\n",
            "\n",
            "    accuracy                           0.96     29357\n",
            "   macro avg       0.95      0.61      0.66     29357\n",
            "weighted avg       0.96      0.96      0.95     29357\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMkth0f4pHDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a19bb271-3f65-4307-a147-226dd9632509"
      },
      "source": [
        "model = FeedForward(300, 300, 150)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "model.train()\n",
        "n_epochs = 60\n",
        "n_iters = 100\n",
        "batch_size = len(X_train) // n_iters\n",
        "\n",
        "for epoch in range(n_epochs):  \n",
        "    epoch_loss = 0\n",
        "    for idx in range(n_iters):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        idx = random.sample(range(len(X_train)), batch_size)\n",
        "\n",
        "        x = X_train[idx]\n",
        "        y_true = y_train[idx]\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred.squeeze(), y_true)\n",
        "        epoch_loss += loss.item() / n_iters\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch {}: train loss: {};'.format(epoch, epoch_loss))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds_train = preds_test = make_predictions(model, X_train)\n",
        "preds_test = make_predictions(model, X_test)\n",
        "\n",
        "train_labels = [label.item() for label in y_train]\n",
        "test_labels = [label.item() for label in y_test]\n",
        "\n",
        "\n",
        "print(classification_report(train_labels, preds_train))\n",
        "print(classification_report(test_labels, preds_test))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 0.45577899217605594;\n",
            "Epoch 1: train loss: 0.2343117994070052;\n",
            "Epoch 2: train loss: 0.19893284708261494;\n",
            "Epoch 3: train loss: 0.18276584520936015;\n",
            "Epoch 4: train loss: 0.16685973629355433;\n",
            "Epoch 5: train loss: 0.15708563975989823;\n",
            "Epoch 6: train loss: 0.15171488553285595;\n",
            "Epoch 7: train loss: 0.14197112061083317;\n",
            "Epoch 8: train loss: 0.13539109043776984;\n",
            "Epoch 9: train loss: 0.1317626535892487;\n",
            "Epoch 10: train loss: 0.12730546973645687;\n",
            "Epoch 11: train loss: 0.12257180735468866;\n",
            "Epoch 12: train loss: 0.12220915049314503;\n",
            "Epoch 13: train loss: 0.12117244623601438;\n",
            "Epoch 14: train loss: 0.11656584806740283;\n",
            "Epoch 15: train loss: 0.11489642336964606;\n",
            "Epoch 16: train loss: 0.11434262789785857;\n",
            "Epoch 17: train loss: 0.11873188726603981;\n",
            "Epoch 18: train loss: 0.1103391744196415;\n",
            "Epoch 19: train loss: 0.11163479052484038;\n",
            "Epoch 20: train loss: 0.10562747403979296;\n",
            "Epoch 21: train loss: 0.10999191753566265;\n",
            "Epoch 22: train loss: 0.11200471796095367;\n",
            "Epoch 23: train loss: 0.11112607181072236;\n",
            "Epoch 24: train loss: 0.10598093450069428;\n",
            "Epoch 25: train loss: 0.10921283420175311;\n",
            "Epoch 26: train loss: 0.10798987105488772;\n",
            "Epoch 27: train loss: 0.1087259425222874;\n",
            "Epoch 28: train loss: 0.10714381724596024;\n",
            "Epoch 29: train loss: 0.10990768596529957;\n",
            "Epoch 30: train loss: 0.10601793818175789;\n",
            "Epoch 31: train loss: 0.10724182628095151;\n",
            "Epoch 32: train loss: 0.10489422306418421;\n",
            "Epoch 33: train loss: 0.10519772894680499;\n",
            "Epoch 34: train loss: 0.1034927517920732;\n",
            "Epoch 35: train loss: 0.10144195411354306;\n",
            "Epoch 36: train loss: 0.10310371972620487;\n",
            "Epoch 37: train loss: 0.10417174093425274;\n",
            "Epoch 38: train loss: 0.10190432455390691;\n",
            "Epoch 39: train loss: 0.1015678707510233;\n",
            "Epoch 40: train loss: 0.10212231475859877;\n",
            "Epoch 41: train loss: 0.10196300290524958;\n",
            "Epoch 42: train loss: 0.10223946347832677;\n",
            "Epoch 43: train loss: 0.10580574490129946;\n",
            "Epoch 44: train loss: 0.10188170399516819;\n",
            "Epoch 45: train loss: 0.10021699383854869;\n",
            "Epoch 46: train loss: 0.10352722141891722;\n",
            "Epoch 47: train loss: 0.10172303423285488;\n",
            "Epoch 48: train loss: 0.10009386993944643;\n",
            "Epoch 49: train loss: 0.10104520626366138;\n",
            "Epoch 50: train loss: 0.09944214142858981;\n",
            "Epoch 51: train loss: 0.09913131795823577;\n",
            "Epoch 52: train loss: 0.09908922664821149;\n",
            "Epoch 53: train loss: 0.10117523431777958;\n",
            "Epoch 54: train loss: 0.10042664300650357;\n",
            "Epoch 55: train loss: 0.09781768452376127;\n",
            "Epoch 56: train loss: 0.09582914602011437;\n",
            "Epoch 57: train loss: 0.09695918876677755;\n",
            "Epoch 58: train loss: 0.09712267726659776;\n",
            "Epoch 59: train loss: 0.09838138505816459;\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98     65178\n",
            "         1.0       0.84      0.49      0.62      3368\n",
            "\n",
            "    accuracy                           0.97     68546\n",
            "   macro avg       0.91      0.74      0.80     68546\n",
            "weighted avg       0.97      0.97      0.97     68546\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98     27931\n",
            "         1.0       0.82      0.47      0.60      1426\n",
            "\n",
            "    accuracy                           0.97     29357\n",
            "   macro avg       0.90      0.73      0.79     29357\n",
            "weighted avg       0.97      0.97      0.97     29357\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIFy_pyHG6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea8f8c2d-3aac-4503-bc88-cc325333f1d9"
      },
      "source": [
        "model = FeedForward(300, 300, 150)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.8)\n",
        "model.train()\n",
        "n_epochs = 60\n",
        "n_iters = 100\n",
        "batch_size = len(X_train) // n_iters\n",
        "\n",
        "for epoch in range(n_epochs):  \n",
        "    epoch_loss = 0\n",
        "    for idx in range(n_iters):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        idx = random.sample(range(len(X_train)), batch_size)\n",
        "\n",
        "        x = X_train[idx]\n",
        "        y_true = y_train[idx]\n",
        "\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred.squeeze(), y_true)\n",
        "        epoch_loss += loss.item() / n_iters\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch {}: train loss: {};'.format(epoch, epoch_loss))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "preds_train = preds_test = make_predictions(model, X_train)\n",
        "preds_test = make_predictions(model, X_test)\n",
        "\n",
        "train_labels = [label.item() for label in y_train]\n",
        "test_labels = [label.item() for label in y_test]\n",
        "\n",
        "\n",
        "print(classification_report(train_labels, preds_train))\n",
        "print(classification_report(test_labels, preds_test))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss: 0.12322368115186688;\n",
            "Epoch 1: train loss: 0.09818455047905446;\n",
            "Epoch 2: train loss: 0.09242620784789324;\n",
            "Epoch 3: train loss: 0.08677276540547611;\n",
            "Epoch 4: train loss: 0.08317872837185855;\n",
            "Epoch 5: train loss: 0.08250761818140746;\n",
            "Epoch 6: train loss: 0.08085583455860613;\n",
            "Epoch 7: train loss: 0.07468647360801699;\n",
            "Epoch 8: train loss: 0.06834786148741841;\n",
            "Epoch 9: train loss: 0.06840197412297129;\n",
            "Epoch 10: train loss: 0.06276670208200812;\n",
            "Epoch 11: train loss: 0.0641672505438328;\n",
            "Epoch 12: train loss: 0.05692399621009827;\n",
            "Epoch 13: train loss: 0.05894658770412206;\n",
            "Epoch 14: train loss: 0.052016238626092656;\n",
            "Epoch 15: train loss: 0.05173601506277919;\n",
            "Epoch 16: train loss: 0.07829651961103083;\n",
            "Epoch 17: train loss: 0.05043162874877455;\n",
            "Epoch 18: train loss: 0.04616866538301109;\n",
            "Epoch 19: train loss: 0.044699518550187355;\n",
            "Epoch 20: train loss: 0.046010530432686214;\n",
            "Epoch 21: train loss: 0.03971729012206197;\n",
            "Epoch 22: train loss: 0.0398909389413893;\n",
            "Epoch 23: train loss: 0.03429247670806944;\n",
            "Epoch 24: train loss: 0.035119110913947205;\n",
            "Epoch 25: train loss: 0.037782968375831866;\n",
            "Epoch 26: train loss: 0.02578171585686504;\n",
            "Epoch 27: train loss: 0.03211644475348294;\n",
            "Epoch 28: train loss: 0.0330941504985094;\n",
            "Epoch 29: train loss: 0.0259851672127843;\n",
            "Epoch 30: train loss: 0.021004826868884257;\n",
            "Epoch 31: train loss: 0.034868280091322944;\n",
            "Epoch 32: train loss: 0.019944109665229914;\n",
            "Epoch 33: train loss: 0.01908403179608286;\n",
            "Epoch 34: train loss: 0.03776300014229491;\n",
            "Epoch 35: train loss: 0.029580253115855146;\n",
            "Epoch 36: train loss: 0.017306046676822007;\n",
            "Epoch 37: train loss: 0.01534296522382647;\n",
            "Epoch 38: train loss: 0.02854025051463395;\n",
            "Epoch 39: train loss: 0.015295392218977218;\n",
            "Epoch 40: train loss: 0.012382928368169819;\n",
            "Epoch 41: train loss: 0.013108574058860541;\n",
            "Epoch 42: train loss: 0.02893464542459697;\n",
            "Epoch 43: train loss: 0.012591326809488232;\n",
            "Epoch 44: train loss: 0.011024451749399304;\n",
            "Epoch 45: train loss: 0.010488183395937083;\n",
            "Epoch 46: train loss: 0.009299655458889902;\n",
            "Epoch 47: train loss: 0.01008320020977408;\n",
            "Epoch 48: train loss: 0.008983387969201432;\n",
            "Epoch 49: train loss: 0.008478661393746737;\n",
            "Epoch 50: train loss: 0.7011814774828962;\n",
            "Epoch 51: train loss: 1.3274994546175;\n",
            "Epoch 52: train loss: 1.3504917079210275;\n",
            "Epoch 53: train loss: 1.413821205496787;\n",
            "Epoch 54: train loss: 1.3839716351032259;\n",
            "Epoch 55: train loss: 1.3496849477291106;\n",
            "Epoch 56: train loss: 1.372273817062377;\n",
            "Epoch 57: train loss: 1.3537186861038208;\n",
            "Epoch 58: train loss: 1.340810748934745;\n",
            "Epoch 59: train loss: 1.3448444890975955;\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      1.00      0.97     65178\n",
            "         1.0       0.00      0.00      0.00      3368\n",
            "\n",
            "    accuracy                           0.95     68546\n",
            "   macro avg       0.48      0.50      0.49     68546\n",
            "weighted avg       0.90      0.95      0.93     68546\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      1.00      0.98     27931\n",
            "         1.0       0.00      0.00      0.00      1426\n",
            "\n",
            "    accuracy                           0.95     29357\n",
            "   macro avg       0.48      0.50      0.49     29357\n",
            "weighted avg       0.91      0.95      0.93     29357\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BHKrZGXca_6",
        "colab_type": "text"
      },
      "source": [
        "## Task 2, advanced\n",
        "\n",
        "Working with nn.Embedding layer \n",
        "\n",
        "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html \n",
        "\n",
        "Read an example below. \n",
        "\n",
        "Please, try to modify your initial version of the SingleLayerPerceptron model to the model with one additional layer: \n",
        "\n",
        "1. Define your vocabulary size  \n",
        "2. Add nn.Embedding layer to the model architecture (vocabulary_size, embedding_size) \n",
        "3. Retrain your model - see if metrics increased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b7jEasvca_7",
        "colab_type": "text"
      },
      "source": [
        "### Useful parts for the part 2: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZHto1Eca_7",
        "colab_type": "text"
      },
      "source": [
        "Refer  to the part 4.3 of the course:\n",
        "\n",
        "https://stepik.org/lesson/262247/\n",
        "\n",
        "It will help you to get the understanding how to use an nn.Embedding layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpIaxekzca_8",
        "colab_type": "text"
      },
      "source": [
        "#####  Let's create a vocabulary: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcUbtp6cca_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_nested(nested):\n",
        "    flatten = []\n",
        "    for item in nested:\n",
        "        if isinstance(item, list):\n",
        "            flatten.extend(item)\n",
        "        else:\n",
        "            flatten.append(item)\n",
        "    return flatten\n",
        "\n",
        "cnt_vocab = Counter(flat_nested(df.cleaned.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FDhKZp8ca_-",
        "colab_type": "code",
        "outputId": "1c12c8eb-616e-4174-f374-0bdd58903616",
        "colab": {}
      },
      "source": [
        "threshold_count_l = 15\n",
        "threshold_count_h = 500\n",
        "threshold_len = 4\n",
        "cleaned_vocab = [token for token, count in cnt_vocab.items() if \n",
        "                     threshold_count_h > count > threshold_count_l and len(token) > threshold_len\n",
        "                ]\n",
        "print(\"Vocab size: {}\".format(len(cleaned_vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 13061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lrKOFDccbAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You will need to have an id for each of your token \n",
        "\n",
        "token_to_id = {v: k for k, v in enumerate(sorted(cleaned_vocab))}\n",
        "id_to_token = {v: k for k, v in token_to_id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}