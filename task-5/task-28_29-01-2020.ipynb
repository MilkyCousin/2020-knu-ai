{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsXRPWN2BGOI"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT51fCRBBGOQ"
   },
   "source": [
    "torch==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2gW25dyBGOU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2814,
     "status": "ok",
     "timestamp": 1580424241727,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "mKkTU2XNLx49",
    "outputId": "b9650f09-2e57-46a0-c5b1-8577f328eb8e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKY7yNrWBGOi"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1580424273166,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "KEGjXaG4BGOr",
    "outputId": "2a294433-8dc3-48f1-9096-94cd19b4c2ad"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTIPZlQmBGO4"
   },
   "source": [
    "In this notebook you will learn pytorch basics, this framework will help you to build simple neural networks during this task.   \n",
    "The first neural network we will try to learn is Feed Forward Neural Network which contain one Fully Connected Layer.  \n",
    "It can have 1 or more fully connected layers, also it could be called as MLP - multilayer perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5ywM13rBGO7"
   },
   "source": [
    "Read about PyTorch here:  \n",
    "https://en.wikipedia.org/wiki/PyTorch\n",
    "\n",
    "And here:\n",
    "\n",
    "https://neurohive.io/ru/tutorial/glubokoe-obuchenie-s-pytorch/\n",
    "\n",
    "While reading these articles probably you will meet some unknown terms: \n",
    "backpropagation algorithm, gradient descent, activation function, loss function, etc.  \n",
    "Please, try to look for an information about why do you need all of these stuff. \n",
    "\n",
    "Answer this questions about Neural Nets: \n",
    "\n",
    "1. In previous tasks we created some features manually, tried to weight our features, tried to select special words for vectorization, how deep learning solves this problem? \n",
    "\n",
    "2. Why do we work with tensors in PyTorch?\n",
    "\n",
    "3. Please, find and read information - why do we need an activation functions in our models? Please, refer to the XOR problem with MLP without activation function, find information about it and answer the previous question. \n",
    "\n",
    "4. Please, answer the following question - what gradient is? Why do we need gradient descent algorithm? Which problem it solves? \n",
    "\n",
    "5. What is backpropagation algorithm? \n",
    "\n",
    "6. What is loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDoUrh2P5TrR"
   },
   "source": [
    "1.  Взять тот же Word2Vec, там есть реализация простой нейронной сети. Именно и она есть способом решения поставленной в вопросе проблемы. Дело в гибкости и настраиваемости параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6lawQyE4iun"
   },
   "source": [
    "2. По сути, тензоры библиотеки pytorch - те же многомерные массивы библиотеки numpy, обладающие аналогичными возможностями. Используються для вычислений. Если ещё глянуть документацию и поверить в написанное (но лучше проверить, что я и сделал), то вычисления на тензорах могут проводиться как на центральном процессоре, так и на графическом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml9Nz4OqFCuo"
   },
   "source": [
    "3.  Активационный процесс заключается в том, когда при необходимом количестве входных данных нейрон передаёт значение далее по сети. Преобразовазованием этого значения занимается функция активации нейрона. Примеры активационных функций - сигмоидная функция (tanh, логистическая, ...), Хэвисайда и т.д.\n",
    "<br>\n",
    "Активационные функции необходимы для гибкости нейронной сети. Ними же решалась задача о линейной несепарабельности данных проблемы XOr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NACw-VV6FPD"
   },
   "source": [
    "4. Пусть $\\Omega \\subset \\mathbb{R}^d (d \\in \\mathbb{N})$ - область в $\\mathbb{R}^d$. Тогда функция $\\phi: \\Omega \\rightarrow \\mathbb{R}$ - скалярное поле.\n",
    "<br>\n",
    "Градиентом $\\phi$ является следующее выражение:\n",
    "$\\nabla \\phi = (\\frac{\\partial \\phi}{\\partial t_1}, \\frac{\\partial \\phi}{\\partial t_2}, \\ldots, \\frac{\\partial \\phi}{\\partial t_d})$,<br>\n",
    "где $\\frac{\\partial \\phi}{\\partial t_j}$ - частная производная $\\phi$ за переменной $t_j$. Градиент отождествляют с направлением в $\\Omega$, в котором $\\phi$ возрастает быстрее всего.\n",
    "<br>\n",
    "Градиентный спуск - метод нахождения локального экстремума некоторой функции с применением её (отрицательного) градиента. В машинном обучении,если рассматривать нейронные сети, то указанный метод используется в обучении модели в качестве принципа обратного распространения ошибки (backpropagation method). Там же и берётся градиент от функции ошибок (она же определяет качество работу нейронной сети в период циклического обучения).\n",
    "<br>\n",
    "Градиентный спуск используется для решения задачи минимизации среднего значения ошибки на выходе нейронной сети, обновляя весовые параметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSmctPpCE3YZ"
   },
   "source": [
    "5. Принцип обратного распространения ошибки - способ вычисления градиента функции, который используется при обновлении параметров многослойного персептрона. Цель - минимизация ошибки и получение желаемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qtrb3bezBSV8"
   },
   "source": [
    "6. Функция потерь - чувствительная к выбросам функция несогласия наблюдаемых данных и тех, что были предсказаны так званой подогнанной функцией модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKmlTe8aBGP4"
   },
   "source": [
    "Read the following article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feedforward_neural_network\n",
    "\n",
    "What is FFNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCbY8qCEB0ra"
   },
   "source": [
    "Нейронная сеть с прямой связью - тип сети, где входные данные обрабатывается из одного конца потока в другой, при этом поток состоит из последовательно соединенных нейронов, которые передают необходимые сигналы.\n",
    "<br>\n",
    "Для такого типа сетей циклы или петли обратной связи не характерны.\n",
    "<br>\n",
    "Простые примеры сетей такого плана: персептроны однослойные и многослойные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbbPBeoHBGQA"
   },
   "source": [
    "## PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDkbQ7i3BGQC"
   },
   "source": [
    "#### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1580424291763,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "Y3MaIiMlBGQH",
    "outputId": "cb426fe9-8232-4748-ba3a-94db4ca1ea2c"
   },
   "outputs": [],
   "source": [
    "# Creating a tensor:\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "\n",
    "print(x.grad)    # returns None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iONaddY3BGQP"
   },
   "source": [
    "print(x.grad) is None because a tensor x is a scalar, so there is nothing to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1524,
     "status": "ok",
     "timestamp": 1580424293207,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "2-0Jsk2cBGQR",
    "outputId": "774e1c05-b972-44be-999c-0c0d6eb63d12"
   },
   "outputs": [],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "y = 20 + x\n",
    "z = (y ** 2) * 2 \n",
    "z.backward()     # auto gradient calculation\n",
    "\n",
    "print(x.grad)    # ∂z/∂x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkRXolFfBGQb"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1580424293988,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "EFpI_dT9BGQf",
    "outputId": "cc687b86-b49f-4db0-e76d-854f5904f198"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cTDg0LjBGQp"
   },
   "outputs": [],
   "source": [
    "# Modify labels dtype to 'int', to make summarizing them possible\n",
    "for column in df.columns: \n",
    "    if column not in ['id', 'comment_text', 'cleaned']:\n",
    "        df[column] = df[column].astype('int32')\n",
    "        \n",
    "# Create a toxicity column (sums all of the toxic labels)\n",
    "df['toxicity'] = df.iloc[:,2:8].sum(axis=1)\n",
    "\n",
    "# Clean data - where toxicity is == 0 \n",
    "clean = df[df['toxicity'] == 0]\n",
    "# Messages, which were labelled as obscene\n",
    "obscene = df[df['obscene'] == 1]\n",
    "\n",
    "# Create a dataset for binary classification \n",
    "df_binary = clean.append(obscene, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dplHZtY5BGQx"
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_binary = df_binary.sample(frac=1)\n",
    "\n",
    "# Reset index of the pd.DataFrame\n",
    "df_binary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1580424301992,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "gnXaVRgxBGQ4",
    "outputId": "08c01fdd-2b7b-4128-902e-5971654f0a99"
   },
   "outputs": [],
   "source": [
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_binary.to_csv(\"../jigsaw-toxic-comment-classification-challenge/df_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315565,
     "status": "ok",
     "timestamp": 1580424616333,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "c5FEsONUBGRA",
    "outputId": "99fce221-dd65-41d6-d058-31123742551d"
   },
   "outputs": [],
   "source": [
    "# Load W2V model \n",
    "import gensim.downloader as api\n",
    "we_model = KeyedVectors.load_word2vec_format('../task-4/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqIIroE8BGRJ"
   },
   "outputs": [],
   "source": [
    "# Make stratified sampling, for example: select 500 examples with obscene == 1, and 500 clean examples. \n",
    "# Select only a small sample of your data (20%), do not train your model on all of the data available \n",
    "# But to make the task easier, make a stratified selection \n",
    "# (number of 1 labels would be approximately equal to number of 0 labels)\n",
    "''' TASK HERE'''\n",
    "\n",
    "df_sample, _ = train_test_split(df_binary, train_size = 0.35)\n",
    "\n",
    "# Split the data on the stratified training and test data sets \n",
    "''' TASK HERE'''\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df_sample, train_size = 0.75, stratify = df_sample.obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1580424704261,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "9b7g9cfsBGRT",
    "outputId": "2e03bc54-3f35-49b3-f9f1-fbb1773f2e4a"
   },
   "outputs": [],
   "source": [
    "print(\"Train shape: {}\".format(df_train.shape))\n",
    "print(\"Test shape: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKsYP7WuBGRb"
   },
   "outputs": [],
   "source": [
    "def get_vectors(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    \n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2EKt_yKBGRj"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors(df_train)\n",
    "X_test, y_test, documents_test = get_vectors(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lazhoAmBGRq"
   },
   "source": [
    "### How to create a simple NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J64yR9qYBGRs"
   },
   "outputs": [],
   "source": [
    "# Modify your model to work with batches, not only single item. \n",
    "''' TASK HERE'''\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logits = nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Makes a forward pass \n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        logits = self.logits(relu)\n",
    "        output = self.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1Xcu9YoPPiR"
   },
   "outputs": [],
   "source": [
    "model = FeedForward(300, 200)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188483,
     "status": "ok",
     "timestamp": 1580425846712,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "eBcxJ8SoBGR0",
    "outputId": "f15486d6-4cb9-47fe-c292-f78f84c705e0"
   },
   "outputs": [],
   "source": [
    "# Initialise the model \n",
    "\n",
    "\n",
    "# Specify loss and optimization functions:\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.BCELoss()\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "# Move model to the training mode\n",
    "model.train()\n",
    "\n",
    "# init n_epochs \n",
    "n_epochs = 10\n",
    "\n",
    "# init number of iterations for one epoch \n",
    "# we want our model during the epoch to walk trough all of the training examples \n",
    "# for batch_size == 1, number of iterations would be equal to number of examples \n",
    "# in the training set \n",
    "n_iters = len(X_train)\n",
    "\n",
    "# initialise batch_size\n",
    "# NOTE! for now it's equal == 1, you need to modify your model to make it possible to work with \n",
    "# batches during training, not only making an update for a single example \n",
    "batch_size = 1\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    for idx in range(n_iters):\n",
    "        \n",
    "        # Selects only 1 sample, modify it to select N samples, N == batch_size\n",
    "        ''' TASK HERE'''\n",
    "        # idx = random.sample(range(len(X_train)), 1) # TIP: You can random sample N examples \n",
    "        \n",
    "        optimizer.zero_grad()    # Forward pass\n",
    "\n",
    "        # Select corresponding data from:\n",
    "        # X (vectors) and labels - for calculating the loss and making a backward pass \n",
    "        # backward pass - updating our weights according to the obtained loss \n",
    "        ''' TASK HERE'''\n",
    "        x = X_train[idx]\n",
    "        y_true = y_train[idx]\n",
    "        \n",
    "        #x = x.to(device)\n",
    "        #y_true = y_true.to(device)\n",
    "\n",
    "        y_pred = model(x)    # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        \n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        loss.backward()   # Backward pass \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))    # Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fXDJlodBGR9"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, X_test, y_test, documents_test, threshold, prints = True): \n",
    "    n_prints = 0\n",
    "    preds = []\n",
    "    for example, label, document in zip(X_test, y_test, documents_test):\n",
    "        pred = model(example)\n",
    "        y_pred = int(pred.item() > threshold)\n",
    "        preds.append(y_pred)\n",
    "        \n",
    "        # Print some examples with obscene documents texts and predicted and true labels \n",
    "        if label.item() == 1.0 and n_prints < 10 and prints:\n",
    "            print(\"Predicted label: {}\".format(y_pred))\n",
    "            print(\"True label: {}\".format(label.item()))\n",
    "            print(\"Document: {}\".format(document))\n",
    "            print(\"*-*-\"*20)\n",
    "            n_prints += 1\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3048,
     "status": "ok",
     "timestamp": 1580425919081,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FpEp2GxyBGSK",
    "outputId": "13364909-5e74-4363-837c-cf124f60954b"
   },
   "outputs": [],
   "source": [
    "# Move model to the eval mode before making a prediction\n",
    "model.eval()\n",
    "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
    "\n",
    "test_labels = [label.item() for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3488,
     "status": "ok",
     "timestamp": 1580425926174,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FL7gteP9Sc_E",
    "outputId": "217ce187-fd60-4e51-a390-d75f514eb469"
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTZtxGDMBGSR",
    "outputId": "a83acbc7-928b-4fb7-a018-de69acc99b45",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results to beat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|         | precision | recall | f1-score | support |\n",
    "|---------|-----------|--------|----------|---------|\n",
    "|0.0      |0.98       |0.99    |0.99      |5724     |\n",
    "|1.0      |0.87       |0.62    |0.72      |337      |\n",
    "|acc      |           |        |0.97      |6061     |\n",
    "|macro avg|0.92       |0.81    |0.86      |6061     |\n",
    "|wghtn avg|0.97       |0.97    |0.97      |6061     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyaDBaimBGSY"
   },
   "source": [
    "## Task 1: \n",
    "\n",
    "#### Find all of the ''' TASK HERE ''' messages. \n",
    "\n",
    "1. Create stratified dataset, make your classes balanced! Train the model. Try to beat the initial score.\n",
    "\n",
    "2. While vectorizing by W2V model, add tf-idf weightning, look at TfidfVectorizer at sklearn. \n",
    "\n",
    "3. Add batch size, modify your model architecture to make it possible to process batches, not only single items. \n",
    "\n",
    "4. Change hidden_size, n_layers, activation function, etc to modify your model. \n",
    "\n",
    "5. Tweak learning rate, see what happened if LR is too small, if too big (0.0001 / 0.8 for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uZidQEdBGSa"
   },
   "outputs": [],
   "source": [
    "# Tip:\n",
    "# Use tf-idf scores calculated by sklearn:\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    # This function is used to replace a default tokenizer in sklearn. \n",
    "    # If you are passing a tokenized documents to the tf-idf vectorizer - \n",
    "    # it would be much faster \n",
    "    return doc\n",
    "\n",
    "def get_idf(tokenized_docs, max_features=180000):\n",
    "    ''' Returns a tf-idf dictionary: \n",
    "            key: word,\n",
    "            value: tf-idf score. \n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        min_df=3,\n",
    "        max_features=max_features,\n",
    "        analyzer='word',\n",
    "        tokenizer=dummy_fun,\n",
    "        preprocessor=dummy_fun,\n",
    "        token_pattern=None,\n",
    "        ngram_range=(1, 1))\n",
    "\n",
    "    vectorizer.fit(tokenized_docs)\n",
    "    idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a5tndQTzT71"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def get_vectors_modified(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    idf_dictionary = get_idf([literal_eval(t) for t in df_sample.cleaned])\n",
    "    #print(idf_dictionary)\n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw] * idf_dictionary[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53288,
     "status": "ok",
     "timestamp": 1580427743606,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "utdl4VsS0GPF",
    "outputId": "7b3e7799-8d90-4ead-aebc-3ee0b2b54c8b"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors_modified(df_train)\n",
    "X_test, y_test, documents_test = get_vectors_modified(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.stack(X_train)\n",
    "y_train = torch.stack(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.stack(X_test)\n",
    "y_test = torch.stack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(torch.chunk(X_test, 32)), len(torch.chunk(y_test, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_mod(model, x_test, y_test, threshold, batch_size):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    x_batches = torch.chunk(x_test, batch_size)\n",
    "    y_batches = torch.chunk(y_test, batch_size)\n",
    "    \n",
    "    assert len(y_batches) == len(x_batches)\n",
    "    \n",
    "    for i in range(len(y_batches)):\n",
    "        x_true = x_batches[i]\n",
    "        y_true = y_batches[i]\n",
    "        \n",
    "        y_pred = model(x_true).detach().squeeze().numpy()\n",
    "        y_pred = [int(prob.item() > threshold) for prob in y_pred]\n",
    "        \n",
    "        predictions.extend(y_pred)\n",
    "        true_labels.extend(y_true)\n",
    "        \n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_train(model, x, y, batch_size):\n",
    "    labels, preds = make_predictions_mod(model, x, y, threshold=0.5, batch_size=batch_size)\n",
    "    return accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWpoc_KImkCH"
   },
   "outputs": [],
   "source": [
    "class FeedForwardModified(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, s1, s2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.s1)\n",
    "        self.fc2 = nn.Linear(self.s1, self.s2)\n",
    "        self.fc3 = nn.Linear(self.s2, 1)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_1 = self.fc1(x)\n",
    "        hidden_1_a = self.relu(hidden_1)\n",
    "        \n",
    "        hidden_2 = self.fc2(hidden_1_a)\n",
    "        hidden_2_a = self.tanh(hidden_2)\n",
    "\n",
    "        pre_output = self.fc3(hidden_2_a)\n",
    "        output = self.sigmoid(pre_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSyHTIbqmvJl"
   },
   "outputs": [],
   "source": [
    "model = FeedForwardModified(300, 180, 90)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: train loss:        0.2072043; train accuracy:        0.9440681\n",
      "Epoch  2: train loss:        0.1784296; train accuracy:        0.9461508\n",
      "Epoch  3: train loss:        0.1735705; train accuracy:        0.9476312\n",
      "Epoch  4: train loss:        0.1748424; train accuracy:        0.9481331\n",
      "Epoch  5: train loss:         0.165678; train accuracy:        0.9492372\n",
      "Epoch  6: train loss:        0.1657029; train accuracy:        0.9492623\n",
      "Epoch  7: train loss:        0.1639954; train accuracy:        0.9494379\n",
      "Epoch  8: train loss:        0.1675978; train accuracy:        0.9501907\n",
      "Epoch  9: train loss:        0.1600007; train accuracy:        0.9508431\n",
      "Epoch 10: train loss:        0.1611213; train accuracy:        0.9507678\n",
      "Epoch 11: train loss:        0.1575864; train accuracy:        0.9511442\n",
      "Epoch 12: train loss:        0.1557904; train accuracy:        0.9516963\n",
      "Epoch 13: train loss:        0.1571727; train accuracy:        0.9518217\n",
      "Epoch 14: train loss:         0.162503; train accuracy:        0.9518217\n",
      "Epoch 15: train loss:        0.1605209; train accuracy:        0.9518217\n",
      "Epoch 16: train loss:        0.1593094; train accuracy:        0.9522985\n",
      "Epoch 17: train loss:        0.1629908; train accuracy:        0.9521229\n",
      "Epoch 18: train loss:        0.1580859; train accuracy:        0.9523236\n",
      "Epoch 19: train loss:        0.1634834; train accuracy:        0.9524491\n",
      "Epoch 20: train loss:        0.1576455; train accuracy:        0.9526749\n",
      "Epoch 21: train loss:        0.1584743; train accuracy:        0.9529258\n",
      "Epoch 22: train loss:        0.1591683; train accuracy:        0.9527502\n",
      "Epoch 23: train loss:        0.1560987; train accuracy:        0.9529007\n",
      "Epoch 24: train loss:        0.1525889; train accuracy:        0.9520727\n",
      "Epoch 25: train loss:          0.15927; train accuracy:        0.9533775\n",
      "Epoch 26: train loss:        0.1567334; train accuracy:        0.9531266\n",
      "Epoch 27: train loss:        0.1578836; train accuracy:        0.9528255\n",
      "Epoch 28: train loss:        0.1553649; train accuracy:        0.9530262\n",
      "Epoch 29: train loss:        0.1580019; train accuracy:        0.9524992\n",
      "Epoch 30: train loss:        0.1545713; train accuracy:        0.9518719\n",
      "Epoch 31: train loss:        0.1541007; train accuracy:        0.9528255\n",
      "Epoch 32: train loss:        0.1520746; train accuracy:        0.9538543\n",
      "Epoch 33: train loss:        0.1556772; train accuracy:        0.9525494\n",
      "Epoch 34: train loss:        0.1543945; train accuracy:        0.9528255\n",
      "Epoch 35: train loss:        0.1554339; train accuracy:        0.9538794\n",
      "Epoch 36: train loss:        0.1566028; train accuracy:        0.9540801\n",
      "Epoch 37: train loss:        0.1556595; train accuracy:        0.9542557\n",
      "Epoch 38: train loss:        0.1534854; train accuracy:        0.9540801\n",
      "Epoch 39: train loss:        0.1562182; train accuracy:        0.9539797\n",
      "Epoch 40: train loss:        0.1534971; train accuracy:        0.9540801\n",
      "Epoch 41: train loss:        0.1538404; train accuracy:        0.9542808\n",
      "Epoch 42: train loss:        0.1554978; train accuracy:        0.9539546\n",
      "Epoch 43: train loss:        0.1595293; train accuracy:        0.9534528\n",
      "Epoch 44: train loss:        0.1489801; train accuracy:        0.9537539\n",
      "Epoch 45: train loss:        0.1521728; train accuracy:        0.9541303\n",
      "Epoch 46: train loss:        0.1525231; train accuracy:        0.9541554\n",
      "Epoch 47: train loss:        0.1507506; train accuracy:        0.9536786\n",
      "Epoch 48: train loss:         0.153475; train accuracy:        0.9543812\n",
      "Epoch 49: train loss:        0.1568164; train accuracy:        0.9522483\n",
      "Epoch 50: train loss:        0.1485963; train accuracy:         0.954858\n",
      "Epoch 51: train loss:        0.1582576; train accuracy:        0.9547325\n",
      "Epoch 52: train loss:        0.1500919; train accuracy:         0.954607\n",
      "Epoch 53: train loss:        0.1514247; train accuracy:        0.9539797\n",
      "Epoch 54: train loss:        0.1518346; train accuracy:         0.954582\n",
      "Epoch 55: train loss:        0.1524583; train accuracy:        0.9541303\n",
      "Epoch 56: train loss:        0.1492985; train accuracy:        0.9549583\n",
      "Epoch 57: train loss:         0.149156; train accuracy:        0.9540299\n",
      "Epoch 58: train loss:        0.1499464; train accuracy:        0.9548831\n",
      "Epoch 59: train loss:        0.1505143; train accuracy:        0.9536786\n",
      "Epoch 60: train loss:        0.1508804; train accuracy:        0.9550587\n",
      "Epoch 61: train loss:         0.143709; train accuracy:        0.9554853\n",
      "Epoch 62: train loss:        0.1531311; train accuracy:        0.9550587\n",
      "Epoch 63: train loss:        0.1527415; train accuracy:        0.9549583\n",
      "Epoch 64: train loss:        0.1510392; train accuracy:        0.9553347\n",
      "Epoch 65: train loss:        0.1515115; train accuracy:        0.9550838\n",
      "Epoch 66: train loss:           0.1542; train accuracy:         0.954858\n",
      "Epoch 67: train loss:        0.1522149; train accuracy:        0.9550838\n",
      "Epoch 68: train loss:        0.1499139; train accuracy:        0.9557362\n",
      "Epoch 69: train loss:        0.1502603; train accuracy:        0.9556108\n",
      "Epoch 70: train loss:        0.1512317; train accuracy:        0.9551591\n",
      "Epoch 71: train loss:        0.1503076; train accuracy:        0.9548078\n",
      "Epoch 72: train loss:        0.1464732; train accuracy:        0.9545067\n",
      "Epoch 73: train loss:        0.1485048; train accuracy:        0.9551842\n",
      "Epoch 74: train loss:        0.1512215; train accuracy:        0.9534779\n",
      "Epoch 75: train loss:        0.1454363; train accuracy:        0.9554602\n",
      "Epoch 76: train loss:        0.1462882; train accuracy:        0.9551089\n",
      "Epoch 77: train loss:        0.1504171; train accuracy:        0.9557613\n",
      "Epoch 78: train loss:        0.1446559; train accuracy:        0.9555606\n",
      "Epoch 79: train loss:        0.1452236; train accuracy:        0.9552093\n",
      "Epoch 80: train loss:         0.146179; train accuracy:        0.9557613\n",
      "Epoch 81: train loss:        0.1534459; train accuracy:        0.9558115\n",
      "Epoch 82: train loss:        0.1492433; train accuracy:        0.9560373\n",
      "Epoch 83: train loss:        0.1481333; train accuracy:        0.9555355\n",
      "Epoch 84: train loss:        0.1477248; train accuracy:        0.9560373\n",
      "Epoch 85: train loss:        0.1506735; train accuracy:        0.9558366\n",
      "Epoch 86: train loss:        0.1458546; train accuracy:        0.9552344\n",
      "Epoch 87: train loss:         0.149877; train accuracy:        0.9553096\n",
      "Epoch 88: train loss:        0.1455526; train accuracy:        0.9555606\n",
      "Epoch 89: train loss:        0.1482304; train accuracy:        0.9549583\n",
      "Epoch 90: train loss:        0.1472823; train accuracy:        0.9560875\n",
      "Epoch 91: train loss:        0.1489297; train accuracy:        0.9557362\n",
      "Epoch 92: train loss:        0.1456116; train accuracy:        0.9553347\n",
      "Epoch 93: train loss:        0.1446813; train accuracy:        0.9556609\n",
      "Epoch 94: train loss:        0.1435565; train accuracy:        0.9558868\n",
      "Epoch 95: train loss:        0.1468227; train accuracy:        0.9562632\n",
      "Epoch 96: train loss:        0.1453116; train accuracy:        0.9561628\n",
      "Epoch 97: train loss:        0.1492303; train accuracy:        0.9557864\n",
      "Epoch 98: train loss:        0.1468796; train accuracy:        0.9552344\n",
      "Epoch 99: train loss:        0.1488236; train accuracy:        0.9560875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-17003a10d894>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "batch_size = 20\n",
    "n_iters = len(X_train) // batch_size\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        idx = random.sample(range(len(X_train)), batch_size)\n",
    "        x = X_train[idx]\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        epoch_loss += loss.item() / n_iters\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    current_acc = accuracy_train(model, X_train, y_train, batch_size)\n",
    "    model.train()\n",
    "        \n",
    "    print('Epoch {:2}: train loss: {:16.7}; train accuracy: {:16.7}'.format(epoch+1, epoch_loss, current_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1764,
     "status": "error",
     "timestamp": 1580430477881,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "zoWGUR7cnl_d",
    "outputId": "7ad84bcb-acdf-4a7b-a9b7-80b87f95f9d0"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_labels, preds = make_predictions_mod(model, X_test, y_test, threshold=0.5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     12540\n",
      "         1.0       0.79      0.31      0.45       743\n",
      "\n",
      "    accuracy                           0.96     13283\n",
      "   macro avg       0.88      0.66      0.71     13283\n",
      "weighted avg       0.95      0.96      0.95     13283\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.957088007227283"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(test_labels, preds))\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы увидим в дальнейшем, качество обучения нейронной сети зависит от параметра learning rate. Покажем, что с большим значением результаты будут неудовлетворительными, а с достаточно низким - долгое время тренировки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Только после того, как Дан научится кодить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdj4E3D5BGSh"
   },
   "source": [
    "## Task 2, advanced\n",
    "\n",
    "Working with nn.Embedding layer \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html \n",
    "\n",
    "Read an example below. \n",
    "\n",
    "Please, try to modify your initial version of the SingleLayerPerceptron model to the model with one additional layer: \n",
    "\n",
    "1. Define your vocabulary size  \n",
    "2. Add nn.Embedding layer to the model architecture (vocabulary_size, embedding_size) \n",
    "3. Retrain your model - see if metrics increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyMP9FAuBGSj"
   },
   "source": [
    "### Useful parts for the part 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0JA6aFDBGSn"
   },
   "source": [
    "Refer  to the part 4.3 of the course:\n",
    "\n",
    "https://stepik.org/lesson/262247/\n",
    "\n",
    "It will help you to get the understanding how to use an nn.Embedding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEf2AuG_BGSq"
   },
   "source": [
    "#####  Let's create a vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUh8Sk3qBGSu"
   },
   "outputs": [],
   "source": [
    "def flat_nested(nested):\n",
    "    flatten = []\n",
    "    for item in nested:\n",
    "        if isinstance(item, list):\n",
    "            flatten.extend(item)\n",
    "        else:\n",
    "            flatten.append(item)\n",
    "    return flatten\n",
    "\n",
    "cnt_vocab = Counter(flat_nested(df.cleaned.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etFoZNG8BGS0",
    "outputId": "fc88eb41-2df6-46c7-d018-8f177874accc"
   },
   "outputs": [],
   "source": [
    "threshold_count_l = 15\n",
    "threshold_count_h = 500\n",
    "threshold_len = 4\n",
    "cleaned_vocab = [token for token, count in cnt_vocab.items() if \n",
    "                     threshold_count_h > count > threshold_count_l and len(token) > threshold_len\n",
    "                ]\n",
    "print(\"Vocab size: {}\".format(len(cleaned_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjyk-id_BGS7"
   },
   "outputs": [],
   "source": [
    "# You will need to have an id for each of your token \n",
    "\n",
    "token_to_id = {v: k for k, v in enumerate(sorted(cleaned_vocab))}\n",
    "id_to_token = {v: k for k, v in token_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task-28_29-01-2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
