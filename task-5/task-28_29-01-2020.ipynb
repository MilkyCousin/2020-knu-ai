{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsXRPWN2BGOI"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT51fCRBBGOQ"
   },
   "source": [
    "torch==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2gW25dyBGOU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2814,
     "status": "ok",
     "timestamp": 1580424241727,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "mKkTU2XNLx49",
    "outputId": "b9650f09-2e57-46a0-c5b1-8577f328eb8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKY7yNrWBGOi"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1580424273166,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "KEGjXaG4BGOr",
    "outputId": "2a294433-8dc3-48f1-9096-94cd19b4c2ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"d'aww\", 'match', 'background', 'colour', \"'m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', \"'m\", 'really', 'trying', 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'ca', \"n't\", 'make', 'real', 'suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  ['explanation', 'edits', 'made', 'username', '...  \n",
       "1  [\"d'aww\", 'match', 'background', 'colour', \"'m...  \n",
       "2  ['hey', 'man', \"'m\", 'really', 'trying', 'edit...  \n",
       "3  ['``', 'ca', \"n't\", 'make', 'real', 'suggestio...  \n",
       "4  ['sir', 'hero', 'chance', 'remember', 'page', ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTIPZlQmBGO4"
   },
   "source": [
    "In this notebook you will learn pytorch basics, this framework will help you to build simple neural networks during this task.   \n",
    "The first neural network we will try to learn is Feed Forward Neural Network which contain one Fully Connected Layer.  \n",
    "It can have 1 or more fully connected layers, also it could be called as MLP - multilayer perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5ywM13rBGO7"
   },
   "source": [
    "Read about PyTorch here:  \n",
    "https://en.wikipedia.org/wiki/PyTorch\n",
    "\n",
    "And here:\n",
    "\n",
    "https://neurohive.io/ru/tutorial/glubokoe-obuchenie-s-pytorch/\n",
    "\n",
    "While reading these articles probably you will meet some unknown terms: \n",
    "backpropagation algorithm, gradient descent, activation function, loss function, etc.  \n",
    "Please, try to look for an information about why do you need all of these stuff. \n",
    "\n",
    "Answer this questions about Neural Nets: \n",
    "\n",
    "1. In previous tasks we created some features manually, tried to weight our features, tried to select special words for vectorization, how deep learning solves this problem? \n",
    "\n",
    "2. Why do we work with tensors in PyTorch?\n",
    "\n",
    "3. Please, find and read information - why do we need an activation functions in our models? Please, refer to the XOR problem with MLP without activation function, find information about it and answer the previous question. \n",
    "\n",
    "4. Please, answer the following question - what gradient is? Why do we need gradient descent algorithm? Which problem it solves? \n",
    "\n",
    "5. What is backpropagation algorithm? \n",
    "\n",
    "6. What is loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDoUrh2P5TrR"
   },
   "source": [
    "1.  Взять тот же Word2Vec, там есть реализация простой нейронной сети. Именно и она есть способом решения поставленной в вопросе проблемы. Дело в гибкости и настраиваемости параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6lawQyE4iun"
   },
   "source": [
    "2. По сути, тензоры библиотеки pytorch - те же многомерные массивы библиотеки numpy, обладающие аналогичными возможностями. Используються для вычислений. Если ещё глянуть документацию и поверить в написанное (но лучше проверить, что я и сделал), то вычисления на тензорах могут проводиться как на центральном процессоре, так и на графическом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml9Nz4OqFCuo"
   },
   "source": [
    "3.  Активационный процесс заключается в том, когда при необходимом количестве входных данных нейрон передаёт значение далее по сети. Преобразовазованием этого значения занимается функция активации нейрона. Примеры активационных функций - сигмоидная функция (tanh, логистическая, ...), Хэвисайда и т.д.\n",
    "<br>\n",
    "Активационные функции необходимы для гибкости нейронной сети. Ними же решалась задача о линейной несепарабельности данных проблемы XOr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NACw-VV6FPD"
   },
   "source": [
    "4. Пусть $\\Omega \\subset \\mathbb{R}^d \\> (d \\in \\mathbb{N})$ - область в $\\mathbb{R}^d$. Тогда функция $\\phi: \\Omega \\rightarrow \\mathbb{R}$ - скалярное поле.\n",
    "<br>\n",
    "Градиентом $\\phi$ является следующее выражение:\n",
    "$\\nabla \\phi = (\\frac{\\partial \\phi}{\\partial t_1}, \\frac{\\partial \\phi}{\\partial t_2}, \\ldots, \\frac{\\partial \\phi}{\\partial t_d})$,<br>\n",
    "где $\\frac{\\partial \\phi}{\\partial t_j}$ - частная производная $\\phi$ за переменной $t_j$. Градиент отождествляют с направлением в $\\Omega$, в котором $\\phi$ возрастает быстрее всего.\n",
    "<br>\n",
    "Градиентный спуск - метод нахождения локального экстремума некоторой функции с применением её (отрицательного) градиента. В машинном обучении,если рассматривать нейронные сети, то указанный метод используется в обучении модели в качестве принципа обратного распространения ошибки (backpropagation method). Там же и берётся градиент от функции ошибок (она же определяет качество работу нейронной сети в период циклического обучения).\n",
    "<br>\n",
    "Градиентный спуск используется для решения задачи минимизации среднего значения ошибки на выходе нейронной сети, обновляя весовые параметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSmctPpCE3YZ"
   },
   "source": [
    "5. Принцип обратного распространения ошибки - способ вычисления градиента функции, который используется при обновлении параметров многослойного персептрона. Цель - минимизация ошибки и получение желаемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qtrb3bezBSV8"
   },
   "source": [
    "6. Функция потерь - чувствительная к выбросам функция несогласия наблюдаемых данных и тех, что были предсказаны так званой подогнанной функцией модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKmlTe8aBGP4"
   },
   "source": [
    "Read the following article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feedforward_neural_network\n",
    "\n",
    "What is FFNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCbY8qCEB0ra"
   },
   "source": [
    "Нейронная сеть с прямой связью - тип сети, где входные данные обрабатывается из одного конца потока в другой, при этом поток состоит из последовательно соединенных нейронов, которые передают необходимые сигналы.\n",
    "<br>\n",
    "Для такого типа сетей циклы или петли обратной связи не характерны.\n",
    "<br>\n",
    "Простые примеры сетей такого плана: персептроны однослойные и многослойные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbbPBeoHBGQA"
   },
   "source": [
    "## PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDkbQ7i3BGQC"
   },
   "source": [
    "#### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1580424291763,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "Y3MaIiMlBGQH",
    "outputId": "cb426fe9-8232-4748-ba3a-94db4ca1ea2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor:\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "\n",
    "print(x.grad)    # returns None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iONaddY3BGQP"
   },
   "source": [
    "print(x.grad) is None because a tensor x is a scalar, so there is nothing to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1524,
     "status": "ok",
     "timestamp": 1580424293207,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "2-0Jsk2cBGQR",
    "outputId": "774e1c05-b972-44be-999c-0c0d6eb63d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([84.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "y = 20 + x\n",
    "z = (y ** 2) * 2 \n",
    "z.backward()     # auto gradient calculation\n",
    "\n",
    "print(x.grad)    # ∂z/∂x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkRXolFfBGQb"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1580424293988,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "EFpI_dT9BGQf",
    "outputId": "cc687b86-b49f-4db0-e76d-854f5904f198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"d'aww\", 'match', 'background', 'colour', \"'m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', \"'m\", 'really', 'trying', 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'ca', \"n't\", 'make', 'real', 'suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  ['explanation', 'edits', 'made', 'username', '...  \n",
       "1  [\"d'aww\", 'match', 'background', 'colour', \"'m...  \n",
       "2  ['hey', 'man', \"'m\", 'really', 'trying', 'edit...  \n",
       "3  ['``', 'ca', \"n't\", 'make', 'real', 'suggestio...  \n",
       "4  ['sir', 'hero', 'chance', 'remember', 'page', ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cTDg0LjBGQp"
   },
   "outputs": [],
   "source": [
    "# Modify labels dtype to 'int', to make summarizing them possible\n",
    "for column in df.columns: \n",
    "    if column not in ['id', 'comment_text', 'cleaned']:\n",
    "        df[column] = df[column].astype('int32')\n",
    "        \n",
    "# Create a toxicity column (sums all of the toxic labels)\n",
    "df['toxicity'] = df.iloc[:,2:8].sum(axis=1)\n",
    "\n",
    "# Clean data - where toxicity is == 0 \n",
    "clean = df[df['toxicity'] == 0]\n",
    "# Messages, which were labelled as obscene\n",
    "obscene = df[df['obscene'] == 1]\n",
    "\n",
    "# Create a dataset for binary classification \n",
    "df_binary = clean.append(obscene, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dplHZtY5BGQx"
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_binary = df_binary.sample(frac=1)\n",
    "\n",
    "# Reset index of the pd.DataFrame\n",
    "df_binary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1580424301992,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "gnXaVRgxBGQ4",
    "outputId": "08c01fdd-2b7b-4128-902e-5971654f0a99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100007</td>\n",
       "      <td>111305</td>\n",
       "      <td>537902dada40ff6d</td>\n",
       "      <td>}}\\n{{WikiProject British Overseas Territories...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wikiproject', 'british', 'overseas', 'territ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137990</td>\n",
       "      <td>153540</td>\n",
       "      <td>9e7310cb54ae26e3</td>\n",
       "      <td>Dicklyon: I removed your so-called references ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['dicklyon', 'removed', 'so-called', 'referenc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121519</td>\n",
       "      <td>135270</td>\n",
       "      <td>d37c704752027a89</td>\n",
       "      <td>Cross en.wiki and Commons matter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['cross', 'en.wiki', 'common', 'matter']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103745</td>\n",
       "      <td>115432</td>\n",
       "      <td>6955d91e68c77f57</td>\n",
       "      <td>Common name\\nIt has come to my attention there...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['common', 'name', 'ha', 'come', 'attention', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78553</td>\n",
       "      <td>87502</td>\n",
       "      <td>ea1468171a1ca93c</td>\n",
       "      <td>\"\\n\\nAppalling English? Excuse me? There is no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'appalling', 'english', 'excuse', 'thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0                id  \\\n",
       "0  100007      111305  537902dada40ff6d   \n",
       "1  137990      153540  9e7310cb54ae26e3   \n",
       "2  121519      135270  d37c704752027a89   \n",
       "3  103745      115432  6955d91e68c77f57   \n",
       "4   78553       87502  ea1468171a1ca93c   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  }}\\n{{WikiProject British Overseas Territories...      0             0   \n",
       "1  Dicklyon: I removed your so-called references ...      0             0   \n",
       "2                   Cross en.wiki and Commons matter      0             0   \n",
       "3  Common name\\nIt has come to my attention there...      0             0   \n",
       "4  \"\\n\\nAppalling English? Excuse me? There is no...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  toxicity  \n",
       "0  ['wikiproject', 'british', 'overseas', 'territ...         0  \n",
       "1  ['dicklyon', 'removed', 'so-called', 'referenc...         0  \n",
       "2           ['cross', 'en.wiki', 'common', 'matter']         0  \n",
       "3  ['common', 'name', 'ha', 'come', 'attention', ...         0  \n",
       "4  ['``', 'appalling', 'english', 'excuse', 'thin...         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315565,
     "status": "ok",
     "timestamp": 1580424616333,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "c5FEsONUBGRA",
    "outputId": "99fce221-dd65-41d6-d058-31123742551d"
   },
   "outputs": [],
   "source": [
    "# Load W2V model \n",
    "import gensim.downloader as api\n",
    "we_model = KeyedVectors.load_word2vec_format('../task-4/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqIIroE8BGRJ"
   },
   "outputs": [],
   "source": [
    "# Make stratified sampling, for example: select 500 examples with obscene == 1, and 500 clean examples. \n",
    "# Select only a small sample of your data (20%), do not train your model on all of the data available \n",
    "# But to make the task easier, make a stratified selection \n",
    "# (number of 1 labels would be approximately equal to number of 0 labels)\n",
    "''' TASK HERE'''\n",
    "\n",
    "df_sample, _ = train_test_split(df_binary, train_size = 0.35)\n",
    "\n",
    "# Split the data on the stratified training and test data sets \n",
    "''' TASK HERE'''\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df_sample, train_size = 0.75, stratify = df_sample.obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1580424704261,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "9b7g9cfsBGRT",
    "outputId": "2e03bc54-3f35-49b3-f9f1-fbb1773f2e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (39860, 12)\n",
      "Test shape: (13287, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: {}\".format(df_train.shape))\n",
    "print(\"Test shape: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKsYP7WuBGRb"
   },
   "outputs": [],
   "source": [
    "def get_vectors(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    \n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2EKt_yKBGRj"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors(df_train)\n",
    "X_test, y_test, documents_test = get_vectors(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lazhoAmBGRq"
   },
   "source": [
    "### How to create a simple NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J64yR9qYBGRs"
   },
   "outputs": [],
   "source": [
    "# Modify your model to work with batches, not only single item. \n",
    "''' TASK HERE'''\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logits = nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Makes a forward pass \n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        logits = self.logits(relu)\n",
    "        output = self.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1Xcu9YoPPiR"
   },
   "outputs": [],
   "source": [
    "model = FeedForward(300, 200)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188483,
     "status": "ok",
     "timestamp": 1580425846712,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "eBcxJ8SoBGR0",
    "outputId": "f15486d6-4cb9-47fe-c292-f78f84c705e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.19409933195800053\n",
      "Epoch 1: train loss: 0.17124371746726866\n",
      "Epoch 2: train loss: 0.16682260921057157\n",
      "Epoch 3: train loss: 0.16466417663887237\n",
      "Epoch 4: train loss: 0.16315643586115666\n",
      "Epoch 5: train loss: 0.1619172285707403\n",
      "Epoch 6: train loss: 0.16080445024210122\n",
      "Epoch 7: train loss: 0.15988265103948143\n",
      "Epoch 8: train loss: 0.15917877726792565\n",
      "Epoch 9: train loss: 0.15858530338181678\n"
     ]
    }
   ],
   "source": [
    "# Initialise the model \n",
    "\n",
    "\n",
    "# Specify loss and optimization functions:\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.BCELoss()\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "# Move model to the training mode\n",
    "model.train()\n",
    "\n",
    "# init n_epochs \n",
    "n_epochs = 10\n",
    "\n",
    "# init number of iterations for one epoch \n",
    "# we want our model during the epoch to walk trough all of the training examples \n",
    "# for batch_size == 1, number of iterations would be equal to number of examples \n",
    "# in the training set \n",
    "n_iters = len(X_train)\n",
    "\n",
    "# initialise batch_size\n",
    "# NOTE! for now it's equal == 1, you need to modify your model to make it possible to work with \n",
    "# batches during training, not only making an update for a single example \n",
    "batch_size = 1\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    for idx in range(n_iters):\n",
    "        \n",
    "        # Selects only 1 sample, modify it to select N samples, N == batch_size\n",
    "        ''' TASK HERE'''\n",
    "        # idx = random.sample(range(len(X_train)), 1) # TIP: You can random sample N examples \n",
    "        \n",
    "        optimizer.zero_grad()    # Forward pass\n",
    "\n",
    "        # Select corresponding data from:\n",
    "        # X (vectors) and labels - for calculating the loss and making a backward pass \n",
    "        # backward pass - updating our weights according to the obtained loss \n",
    "        ''' TASK HERE'''\n",
    "        x = X_train[idx]\n",
    "        y_true = y_train[idx]\n",
    "        \n",
    "        #x = x.to(device)\n",
    "        #y_true = y_true.to(device)\n",
    "\n",
    "        y_pred = model(x)    # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        \n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        loss.backward()   # Backward pass \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))    # Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fXDJlodBGR9"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, X_test, y_test, documents_test, threshold): \n",
    "    n_prints = 0\n",
    "    preds = []\n",
    "    for example, label, document in zip(X_test, y_test, documents_test):\n",
    "        pred = model(example)\n",
    "        y_pred = int(pred.item() > threshold)\n",
    "        preds.append(y_pred)\n",
    "        \n",
    "        # Print some examples with obscene documents texts and predicted and true labels \n",
    "        if label.item() == 1.0 and n_prints < 10:\n",
    "            print(\"Predicted label: {}\".format(y_pred))\n",
    "            print(\"True label: {}\".format(label.item()))\n",
    "            print(\"Document: {}\".format(document))\n",
    "            print(\"*-*-\"*20)\n",
    "            n_prints += 1\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3048,
     "status": "ok",
     "timestamp": 1580425919081,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FpEp2GxyBGSK",
    "outputId": "13364909-5e74-4363-837c-cf124f60954b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: camp lazlo do you like it or not?-\n",
      "I don't like camp lazlo, it bores me and lazlo is an idiot.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: You guys have a lot of balls whining about WP transgressions after the displays of lack of respect for these policies yourselves! Man WP displays it's ignorance and bias for a few childish editors in these examples. Compete hoax. The idiots pushing allthe rules cry realquick when the same techniques are spouted towards them.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: FUCK YOU WIKIPEIA YOU CANT STOP US!!!!!!!!!!!!!!!!\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Your threats don't work, motherfucker. I don't care if you block this IP address forever. You'll never know who I am, you'll just prevent other people from using Wikipedia (which is fine by me) and I will continue to challenge your lies. I have plenty of IP addresses and plenty of user names.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Yer all a bunch of wankers! pppptttthhhh! nipple...\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: u suckkkkkkkkkkkkkkk\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Hello, you disgusting transsexual \n",
      "\n",
      "You are a grotesque blight upon the earth. Please kill yourself.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: For being a massive faggot\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: guys like you annoy me so much i fucking hate guys like you i don't give a fuck if they close my account i just hate guys like you you stupid motherfucker googdbye\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: All suuukkks ma deeeekk\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "# Move model to the eval mode before making a prediction\n",
    "model.eval()\n",
    "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
    "\n",
    "test_labels = [label.item() for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3488,
     "status": "ok",
     "timestamp": 1580425926174,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FL7gteP9Sc_E",
    "outputId": "217ce187-fd60-4e51-a390-d75f514eb469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98     12553\n",
      "         1.0       0.74      0.26      0.39       733\n",
      "\n",
      "    accuracy                           0.95     13286\n",
      "   macro avg       0.85      0.63      0.68     13286\n",
      "weighted avg       0.95      0.95      0.94     13286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTZtxGDMBGSR",
    "outputId": "a83acbc7-928b-4fb7-a018-de69acc99b45",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      5724\n",
      "         1.0       0.87      0.62      0.72       337\n",
      "\n",
      "    accuracy                           0.97      6061\n",
      "   macro avg       0.92      0.81      0.86      6061\n",
      "weighted avg       0.97      0.97      0.97      6061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyaDBaimBGSY"
   },
   "source": [
    "## Task 1: \n",
    "\n",
    "#### Find all of the ''' TASK HERE ''' messages. \n",
    "\n",
    "1. Create stratified dataset, make your classes balanced! Train the model. Try to beat the initial score.\n",
    "\n",
    "2. While vectorizing by W2V model, add tf-idf weightning, look at TfidfVectorizer at sklearn. \n",
    "\n",
    "3. Add batch size, modify your model architecture to make it possible to process batches, not only single items. \n",
    "\n",
    "4. Change hidden_size, n_layers, activation function, etc to modify your model. \n",
    "\n",
    "5. Tweak learning rate, see what happened if LR is too small, if too big (0.0001 / 0.8 for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uZidQEdBGSa"
   },
   "outputs": [],
   "source": [
    "# Tip:\n",
    "# Use tf-idf scores calculated by sklearn:\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    # This function is used to replace a default tokenizer in sklearn. \n",
    "    # If you are passing a tokenized documents to the tf-idf vectorizer - \n",
    "    # it would be much faster \n",
    "    return doc\n",
    "\n",
    "def get_idf(tokenized_docs, max_features=180000):\n",
    "    ''' Returns a tf-idf dictionary: \n",
    "            key: word,\n",
    "            value: tf-idf score. \n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        min_df=3,\n",
    "        max_features=max_features,\n",
    "        analyzer='word',\n",
    "        tokenizer=dummy_fun,\n",
    "        preprocessor=dummy_fun,\n",
    "        token_pattern=None,\n",
    "        ngram_range=(1, 1))\n",
    "\n",
    "    vectorizer.fit(tokenized_docs)\n",
    "    idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a5tndQTzT71"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def get_vectors_modified(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    idf_dictionary = get_idf([literal_eval(t) for t in df_sample.cleaned])\n",
    "    #print(idf_dictionary)\n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw] * idf_dictionary[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53288,
     "status": "ok",
     "timestamp": 1580427743606,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "utdl4VsS0GPF",
    "outputId": "7b3e7799-8d90-4ead-aebc-3ee0b2b54c8b"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors_modified(df_train)\n",
    "X_test, y_test, documents_test = get_vectors_modified(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWpoc_KImkCH"
   },
   "outputs": [],
   "source": [
    "class FeedForwardModified(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, hidden_size_3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        self.hidden_size_2 = hidden_size_2\n",
    "        self.hidden_size_3 = hidden_size_3\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size_1)\n",
    "        self.fc2 = nn.Linear(self.hidden_size_1, self.hidden_size_2)\n",
    "        self.fc3 = nn.Linear(self.hidden_size_2, self.hidden_size_3)\n",
    "        self.fc4 = nn.Linear(self.hidden_size_3, 1)\n",
    "        \n",
    "        self.id1 = nn.Identity()\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_1 = self.fc1(x)\n",
    "        hidden_1_a = self.relu(hidden_1)\n",
    "        \n",
    "        ident_1 = self.id1(hidden_1_a)\n",
    "        ident_1_a = self.tanh(ident_1)\n",
    "        \n",
    "        hidden_2 = self.fc2(ident_1_a)\n",
    "        hidden_2_a = self.relu(hidden_2)\n",
    "        \n",
    "        hidden_3 = self.fc3(hidden_2_a)\n",
    "        hidden_3_a = self.tanh(hidden_3)\n",
    "\n",
    "        pre_output = self.fc4(hidden_3_a)\n",
    "        output = self.sigmoid(pre_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSyHTIbqmvJl"
   },
   "outputs": [],
   "source": [
    "model = FeedForwardModified(300, 180, 140, 100)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.06290903160718565\n",
      "Epoch 1: train loss: 0.05589651303843217\n",
      "Epoch 2: train loss: 0.05470624460878483\n",
      "Epoch 3: train loss: 0.053938408432902145\n",
      "Epoch 4: train loss: 0.053437072904575715\n",
      "Epoch 5: train loss: 0.053143382596586276\n",
      "Epoch 6: train loss: 0.052851769917066825\n",
      "Epoch 7: train loss: 0.052501616477922605\n",
      "Epoch 8: train loss: 0.05232161793902307\n",
      "Epoch 9: train loss: 0.052020618092366584\n",
      "Epoch 10: train loss: 0.051934641602036466\n",
      "Epoch 11: train loss: 0.051717989485930024\n",
      "Epoch 12: train loss: 0.05149919333321875\n",
      "Epoch 13: train loss: 0.05125955690112093\n",
      "Epoch 14: train loss: 0.05113732726052966\n",
      "Epoch 15: train loss: 0.050949973418479594\n",
      "Epoch 16: train loss: 0.05069453743196052\n",
      "Epoch 17: train loss: 0.05053496540881946\n",
      "Epoch 18: train loss: 0.050383754960161876\n",
      "Epoch 19: train loss: 0.05027494401046628\n",
      "Epoch 20: train loss: 0.05012431315408447\n",
      "Epoch 21: train loss: 0.05002010815749214\n",
      "Epoch 22: train loss: 0.049912466820662985\n",
      "Epoch 23: train loss: 0.049783022697219285\n",
      "Epoch 24: train loss: 0.04965049512659463\n",
      "Epoch 25: train loss: 0.04956458864163012\n",
      "Epoch 26: train loss: 0.04953924107569482\n",
      "Epoch 27: train loss: 0.049338562201474874\n",
      "Epoch 28: train loss: 0.04929808650908647\n",
      "Epoch 29: train loss: 0.04924753875745264\n",
      "Epoch 30: train loss: 0.04906370284303812\n",
      "Epoch 31: train loss: 0.04885708283243352\n",
      "Epoch 32: train loss: 0.0488433077255895\n",
      "Epoch 33: train loss: 0.0486937539016476\n",
      "Epoch 34: train loss: 0.048570610137925345\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-b7b043f380b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {}: train loss: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    104\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.005)\n",
    "\n",
    "model.train()\n",
    "\n",
    "n_epochs = 50\n",
    "n_iters = len(X_train)\n",
    "\n",
    "batch_size = 3\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    for idx in range(0, n_iters, batch_size):\n",
    "\n",
    "        optimizer.zero_grad()    # Forward pass\n",
    "\n",
    "        x = X_train[idx:idx + batch_size-1]\n",
    "        y_true = y_train[idx:idx + batch_size-1]\n",
    "        \n",
    "        x = torch.stack(x)\n",
    "        y_true = torch.stack(y_true)\n",
    "\n",
    "        y_pred = model(x)    # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        \n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        loss.backward()   # Backward pass \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))    # Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1764,
     "status": "error",
     "timestamp": 1580430477881,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "zoWGUR7cnl_d",
    "outputId": "7ad84bcb-acdf-4a7b-a9b7-80b87f95f9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: camp lazlo do you like it or not?-\n",
      "I don't like camp lazlo, it bores me and lazlo is an idiot.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: You guys have a lot of balls whining about WP transgressions after the displays of lack of respect for these policies yourselves! Man WP displays it's ignorance and bias for a few childish editors in these examples. Compete hoax. The idiots pushing allthe rules cry realquick when the same techniques are spouted towards them.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: FUCK YOU WIKIPEIA YOU CANT STOP US!!!!!!!!!!!!!!!!\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "FUCK\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Your threats don't work, motherfucker. I don't care if you block this IP address forever. You'll never know who I am, you'll just prevent other people from using Wikipedia (which is fine by me) and I will continue to challenge your lies. I have plenty of IP addresses and plenty of user names.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Yer all a bunch of wankers! pppptttthhhh! nipple...\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: u suckkkkkkkkkkkkkkk\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Hello, you disgusting transsexual \n",
      "\n",
      "You are a grotesque blight upon the earth. Please kill yourself.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: For being a massive faggot\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: guys like you annoy me so much i fucking hate guys like you i don't give a fuck if they close my account i just hate guys like you you stupid motherfucker googdbye\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: All suuukkks ma deeeekk\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
    "test_labels = [label.item() for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     12553\n",
      "         1.0       0.81      0.29      0.43       733\n",
      "\n",
      "    accuracy                           0.96     13286\n",
      "   macro avg       0.88      0.64      0.70     13286\n",
      "weighted avg       0.95      0.96      0.95     13286\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9570976968237243"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(test_labels, preds))\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы увидим в дальнейшем, качество обучения нейронной сети зависит от параметра learning rate. Покажем, что с большим значением результаты будут неудовлетворительными, а с достаточно низким - долгое время тренировки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Только после того, как Дан научится кодить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdj4E3D5BGSh"
   },
   "source": [
    "## Task 2, advanced\n",
    "\n",
    "Working with nn.Embedding layer \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html \n",
    "\n",
    "Read an example below. \n",
    "\n",
    "Please, try to modify your initial version of the SingleLayerPerceptron model to the model with one additional layer: \n",
    "\n",
    "1. Define your vocabulary size  \n",
    "2. Add nn.Embedding layer to the model architecture (vocabulary_size, embedding_size) \n",
    "3. Retrain your model - see if metrics increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyMP9FAuBGSj"
   },
   "source": [
    "### Useful parts for the part 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0JA6aFDBGSn"
   },
   "source": [
    "Refer  to the part 4.3 of the course:\n",
    "\n",
    "https://stepik.org/lesson/262247/\n",
    "\n",
    "It will help you to get the understanding how to use an nn.Embedding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEf2AuG_BGSq"
   },
   "source": [
    "#####  Let's create a vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUh8Sk3qBGSu"
   },
   "outputs": [],
   "source": [
    "def flat_nested(nested):\n",
    "    flatten = []\n",
    "    for item in nested:\n",
    "        if isinstance(item, list):\n",
    "            flatten.extend(item)\n",
    "        else:\n",
    "            flatten.append(item)\n",
    "    return flatten\n",
    "\n",
    "cnt_vocab = Counter(flat_nested(df.cleaned.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etFoZNG8BGS0",
    "outputId": "fc88eb41-2df6-46c7-d018-8f177874accc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 13061\n"
     ]
    }
   ],
   "source": [
    "threshold_count_l = 15\n",
    "threshold_count_h = 500\n",
    "threshold_len = 4\n",
    "cleaned_vocab = [token for token, count in cnt_vocab.items() if \n",
    "                     threshold_count_h > count > threshold_count_l and len(token) > threshold_len\n",
    "                ]\n",
    "print(\"Vocab size: {}\".format(len(cleaned_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjyk-id_BGS7"
   },
   "outputs": [],
   "source": [
    "# You will need to have an id for each of your token \n",
    "\n",
    "token_to_id = {v: k for k, v in enumerate(sorted(cleaned_vocab))}\n",
    "id_to_token = {v: k for k, v in token_to_id.items()}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task-28_29-01-2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
