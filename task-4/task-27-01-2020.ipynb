{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models import FastText\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "ne.set_num_threads(ne.detect_number_of_cores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokenizer, lemmatizer, stop_words, punctuation, text): \n",
    "    tokens = tokenizer(text.lower())\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return [token for token in lemmas if token not in stop_words and token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_load = True\n",
    "\n",
    "if not bool_load:\n",
    "    df['cleaned'] = df.comment_text.apply(lambda x: preprocess_text(word_tokenize, lemmatizer, stop_words, punctuation, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save = False\n",
    "\n",
    "if bool_save:\n",
    "    df.to_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>5787</td>\n",
       "      <td>0f7b032528a63cc0</td>\n",
       "      <td>Cliodhna Doyle\\nPlease don't create articles a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['cliodhna', 'doyle', 'please', \"n't\", 'create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100049</th>\n",
       "      <td>100049</td>\n",
       "      <td>177804f66f70545f</td>\n",
       "      <td>\"\\n\\nThis not being fair is something you and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'fair', 'something', 'agree', 'edit', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137411</th>\n",
       "      <td>137411</td>\n",
       "      <td>df3fad33a597d0e1</td>\n",
       "      <td>Europa (moon)\\nI like the work youve done on E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['europa', 'moon', 'like', 'work', 'youve', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118051</th>\n",
       "      <td>118051</td>\n",
       "      <td>76952d036894ba60</td>\n",
       "      <td>Really?  You can't see the blown highlights in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['really', 'ca', \"n't\", 'see', 'blown', 'highl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76429</th>\n",
       "      <td>76429</td>\n",
       "      <td>cc9dfd28c7df628f</td>\n",
       "      <td>Oh ok... thanks for that. ►   ( Talk ♥ Contrib...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['oh', 'ok', '...', 'thanks', '►', 'talk', '♥'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                id  \\\n",
       "5787          5787  0f7b032528a63cc0   \n",
       "100049      100049  177804f66f70545f   \n",
       "137411      137411  df3fad33a597d0e1   \n",
       "118051      118051  76952d036894ba60   \n",
       "76429        76429  cc9dfd28c7df628f   \n",
       "\n",
       "                                             comment_text  toxic  \\\n",
       "5787    Cliodhna Doyle\\nPlease don't create articles a...      0   \n",
       "100049  \"\\n\\nThis not being fair is something you and ...      0   \n",
       "137411  Europa (moon)\\nI like the work youve done on E...      0   \n",
       "118051  Really?  You can't see the blown highlights in...      0   \n",
       "76429   Oh ok... thanks for that. ►   ( Talk ♥ Contrib...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "5787               0        0       0       0              0   \n",
       "100049             0        0       0       0              0   \n",
       "137411             0        0       0       0              0   \n",
       "118051             0        0       0       0              0   \n",
       "76429              0        0       0       0              0   \n",
       "\n",
       "                                                  cleaned  \n",
       "5787    ['cliodhna', 'doyle', 'please', \"n't\", 'create...  \n",
       "100049  ['``', 'fair', 'something', 'agree', 'edit', '...  \n",
       "137411  ['europa', 'moon', 'like', 'work', 'youve', 'd...  \n",
       "118051  ['really', 'ca', \"n't\", 'see', 'blown', 'highl...  \n",
       "76429   ['oh', 'ok', '...', 'thanks', '►', 'talk', '♥'...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our first model based on the vocabulary from df_sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With initialization model trained for 5 epochs \n",
    "\n",
    "df_sample_cleaned_list = [literal_eval(s) for s in df_sample.cleaned.tolist()]\n",
    "\n",
    "model = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "         size=100,      # embedding vector size\n",
    "         min_count=5,   # consider words that occured at least 5 times\n",
    "         window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99633734, 117950070)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training the model \n",
    "\n",
    "model.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=30\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab # to look at vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.6437145471572876),\n",
       " ('person', 0.6037046909332275),\n",
       " ('everyone', 0.5745449066162109),\n",
       " ('thing', 0.5650192499160767),\n",
       " ('way', 0.5321717858314514),\n",
       " ('admins', 0.5284237265586853),\n",
       " ('guy', 0.5068493485450745),\n",
       " ('wikipedians', 0.5053339004516602),\n",
       " ('someone', 0.49681389331817627),\n",
       " ('editor', 0.4963911771774292)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next approach is to try to use the already pretrained model, which can be downloaded from here:\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "model:   \n",
    "GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\n",
    "    os.getcwd() + os.sep + \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to use GloVe model too and experiment with it: <- later\n",
    "# import gensim.downloader as api\n",
    "# model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Cosine similarity\n",
    "\n",
    "To measure how similar two words are, we need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows: \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "where $u.v$ is the dot product (or inner product) of two vectors, $||u||_2$ is the norm (or length) of the vector $u$, and $\\theta$ is the angle between $u$ and $v$. This similarity depends on the angle between $u$ and $v$. If $u$ and $v$ are very similar, their cosine similarity will be close to 1; if they are dissimilar, the cosine similarity will take a smaller value. \n",
    "\n",
    "<img src=\"cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **Figure 1**: The cosine of the angle between two vectors is a measure of how similar they are</center></caption>\n",
    "\n",
    "**Exercise**: Implement the function `cosine_similarity()` to evaluate similarity between word vectors.\n",
    "\n",
    "**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(w1, w2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between w1 and w2\n",
    "    \n",
    "    Arguments:\n",
    "        w1 : word vector        \n",
    "        w2 : word vector \n",
    "    Returns:\n",
    "        cosine_similarity \n",
    "    \"\"\"\n",
    "    if (not np.any(w1) or not np.any(w2)): # check input is not zero-vector\n",
    "        return 0\n",
    "    \n",
    "    # Dot product between w1 and w2\n",
    "    dot = np.dot(w1, w2)\n",
    "    # L2 norm of w1\n",
    "    norm_u = np.linalg.norm(w1) \n",
    "    # L2 norm of w2 \n",
    "    norm_v = np.linalg.norm(w2) \n",
    "    # Cosine similarity \n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "father = model.get_vector(\"father\")\n",
    "mother = model.get_vector(\"mother\")\n",
    "\n",
    "ball = model.get_vector(\"ball\")\n",
    "crocodile = model.get_vector(\"crocodile\")\n",
    "\n",
    "france = model.get_vector(\"france\")\n",
    "paris = model.get_vector(\"paris\")\n",
    "italy = model.get_vector(\"italy\")\n",
    "rome = model.get_vector(\"rome\")\n",
    "\n",
    "kiev = model.get_vector(\"kiev\")\n",
    "ukraine = model.get_vector(\"ukraine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.79014826\n",
      "cosine_similarity(ball, crocodile) =  0.10283584\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.1988747\n",
      "cosine_similarity(kiev, ukraine) =  0.3738725\n"
     ]
    }
   ],
   "source": [
    "fast_print = lambda u, v, tag1, tag2: print(\n",
    "    \"cosine_similarity({t1}, {t2}) = \".format(t1 = tag1, t2 = tag2), cosine_similarity(u, v)\n",
    ")\n",
    "\n",
    "fast_print(father, mother, \"father\", \"mother\")\n",
    "fast_print(ball, crocodile, \"ball\", \"crocodile\")\n",
    "fast_print(france - paris, rome - italy, \"france - paris\", \"rome - italy\")\n",
    "fast_print(kiev, ukraine, \"kiev\", \"ukraine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approximate expected output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.79014826\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(ball, crocodile)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.10283585\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.421037\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Word analogy task\n",
    "\n",
    "In the word analogy task, we complete the sentence <font color='brown'>\"*a* is to *b* as *c* is to **____**\"</font>. An example is <font color='brown'> '*man* is to *woman* as *king* is to *queen*' </font>. In detail, we are trying to find a word *d*, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \\approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity. \n",
    "\n",
    "**Exercise**: Complete the code below to be able to perform word analogies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note***: here you will need to complete a function in the sections, which are marked as:\n",
    "\n",
    "```\n",
    "# ----- Start ----- #\n",
    "Your code should be written in-between the lines\n",
    "# ------ End ------ #\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_analogy(word_1, word_2, word_3, model):\n",
    "    \"\"\"\n",
    "    Finds the word to complete analogy (see explanation above): a is to b as c is to ____. \n",
    "    \n",
    "    Arguments:\n",
    "    word_1 -- a word, string\n",
    "    word_2 -- a word, string\n",
    "    word_3 -- a word, string\n",
    "    model -- word embeddings model \n",
    "    \n",
    "    Returns:\n",
    "    best_word --  the word such that v_1 - v_2 is close to v_best_word - v_3, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    # convert words to lower case\n",
    "    word_1, word_2, word_3 = word_1.lower(), word_2.lower(), word_3.lower()\n",
    "    \n",
    "    # ----- Start ----- #\n",
    "    # Get the word embeddings v_a, v_b and v_c (≈1-3 lines)\n",
    "    fast_get = lambda word: model.get_vector(word)\n",
    "    e_1, e_2, e_3 = tuple(map(fast_get, [word_1, word_2, word_3]))\n",
    "    # ------ End ------ #\n",
    "    \n",
    "    words = list(model.vocab.keys())\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None\n",
    "\n",
    "    # Loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        e_j = fast_get(w)\n",
    "        # to avoid best_word being one of the input words, skip them and continue iteration.\n",
    "        if w in [word_1, word_2, word_3]:\n",
    "            continue\n",
    "        \n",
    "        # ----- Start ----- #\n",
    "        # Compute cosine similarity between the vector (e_2 - e_1) and the vector ((w's vector) - e_3)\n",
    "        cosine_sim = cosine_similarity(e_2 - e_1, e_j - e_3)\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "        # do not forget to set new max_cosine_sim to the current value and best_word as well\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        # ------ End ------ #\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: king -> queen\n",
      "bad -> good :: sad -> wonderful\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [\n",
    "    ('man', 'woman', 'king'), \n",
    "    ('bad', 'good', 'sad'), \n",
    "    ('man', 'woman', 'boy'), \n",
    "    ('small', 'smaller', 'large')\n",
    "]\n",
    "\n",
    "for triad in triads_to_try:\n",
    "    print('{} -> {} :: {} -> {}'.format(*triad, find_word_analogy(*triad, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **man -> woman** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         king -> queen\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **bad -> good** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         sad -> wonderful\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next part of the task is to:  \n",
    "\n",
    "1. Train your own W2V model using the proposed method above. Use all of the tokens created after your preprocessing pipeline in the previous tasks. (deleting stop_words, punctuation, lowercasing, etc - play as you want).  \n",
    "2. Use obtained vectors to obtain text vectors using such pipeline: \n",
    "  1. For each word in a preprocessed text, get a word vector from the W2V model. \n",
    "  2. Add them together to obtain vectors for texts (sum them together, or get mean vector) \n",
    "3. Use obtained text vectors as a text representation to perform a text classification task.  \n",
    "   Proposed - use binary classification (for example: select only 'obscene' text and clean and try to distinguish them one from another)\n",
    "4. Calculate the metrics - TP, FP, FN, TN, precision, recall, F1 score, F2 score, accurary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class callback_custom(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "         self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Iteration {:3}\".format(self.epoch+1))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   1\n",
      "Iteration   2\n",
      "Iteration   3\n",
      "Iteration   4\n",
      "Iteration   5\n"
     ]
    }
   ],
   "source": [
    "# init w2v model\n",
    "n_dimensions = 300\n",
    "\n",
    "model_w2v = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "                     size=n_dimensions, min_count=5, window=5,\n",
    "                     callbacks=[callback_custom()]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   6\n",
      "Iteration   7\n",
      "Iteration   8\n",
      "Iteration   9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
	  "...",
      "Iteration  45\n",
      "Iteration  46\n",
      "Iteration  47\n",
      "Iteration  48\n",
      "Iteration  49\n",
      "Iteration  50\n",
      "Iteration  51\n",
      "Iteration  52\n",
      "Iteration  53\n",
      "Iteration  54\n",
      "Iteration  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166060871, 196583450)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_w2v.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_w2v.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.5206615328788757),\n",
       " ('thing', 0.4942361116409302),\n",
       " ('person', 0.4668040871620178),\n",
       " (\"n't\", 0.4607079327106476),\n",
       " ('way', 0.44727379083633423),\n",
       " ('everyone', 0.4458949565887451),\n",
       " ('admins', 0.4422728419303894),\n",
       " ('editor', 0.43506354093551636),\n",
       " ('someone', 0.4273918867111206),\n",
       " ('would', 0.42714184522628784)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 0.48523271083831787),\n",
       " ('two', 0.47902488708496094),\n",
       " ('even', 0.4700774550437927),\n",
       " ('every', 0.44541630148887634),\n",
       " ('way', 0.44086700677871704),\n",
       " ('article', 0.43976253271102905),\n",
       " (\"'s\", 0.4374009966850281),\n",
       " ('think', 0.43113958835601807),\n",
       " ('first', 0.42464885115623474),\n",
       " ('another', 0.41953933238983154)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save_model = False\n",
    "\n",
    "if bool_save_model:\n",
    "    model_w2v.wv.save_word2vec_format('w2v_df_t2_clnd_sample.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_vectors = model_w2v.wv # getting keyed vectors from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35290"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def is_not_outliner(\n",
    "    word: str, \n",
    "    counts: Counter,\n",
    "    counts_lim_min: int = 5,\n",
    "    length_lim_min: int = 3,\n",
    "    length_lim_max: int = 20):\n",
    "    return (counts[word] > counts_lim_min and (length_lim_min <= len(word) <= length_lim_max))\n",
    "\n",
    "\n",
    "flat_nested = lambda fl: [e for l in fl for e in l]\n",
    "fast_vocab = lambda l: set(flat_nested(l))\n",
    "\n",
    "\n",
    "mess = [literal_eval(e) for e in df['cleaned'].tolist()]\n",
    "cnts = Counter(flat_nested(mess))\n",
    "cleaned_vocab = [t for t in fast_vocab(mess) if is_not_outliner(t, cnts)]\n",
    "len(cleaned_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 2, 'c': 2}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{t:v for t in ['a', 'b', 'c'] for v in range(3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              texts\n",
      "0      1           ['cocksucker', 'piss', 'around', 'work']\n",
      "1      1  ['gay', 'antisemmitian', 'archangel', 'white',...\n",
      "2      1                ['fuck', 'filthy', 'mother', 'dry']\n",
      "3      1  ['stupid', 'peace', 'shit', 'stop', 'deleting'...\n",
      "4      1  ['=tony', 'sidaway', 'obviously', 'fistfuckee'...\n",
      "\n",
      "        label                                              texts\n",
      "151218      0  ['``', 'second', 'time', 'asking', 'view', 'co...\n",
      "151219      0  ['ashamed', 'horrible', 'thing', 'put', 'talk'...\n",
      "151220      0  ['spitzer', 'umm', 'actual', 'article', 'prost...\n",
      "151221      0  ['look', 'like', 'wa', 'actually', 'put', 'spe...\n",
      "151222      0  ['``', '...', 'really', \"n't\", 'think', 'under...\n"
     ]
    }
   ],
   "source": [
    "text_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cleaned']\n",
    "\n",
    "temp = df[[text_categories[4], text_categories[-1]]]\n",
    "\n",
    "temp_n = temp[~df[text_categories[:-1]].any(axis = 'columns')]\n",
    "temp_i = temp[df.insult != 0]\n",
    "\n",
    "insulting_and_neutral = temp_i.append(temp_n).reset_index(drop = True)\n",
    "insulting_and_neutral.columns = ['label', 'texts']\n",
    "\n",
    "del temp, temp_n, temp_i\n",
    "\n",
    "print(\n",
    "    insulting_and_neutral.head(),\n",
    "    insulting_and_neutral.tail(),\n",
    "    sep = '\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25\n",
    "N = 75000\n",
    "\n",
    "i_and_n_sample = insulting_and_neutral.sample(N)\n",
    "\n",
    "X_train_t, X_test_t, Y_train, Y_test = train_test_split(\n",
    "    i_and_n_sample['texts'], i_and_n_sample['label'],\n",
    "    test_size = P,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "X_train_t = [literal_eval(s) for s in X_train_t.reset_index(drop = True)]\n",
    "X_test_t = [literal_eval(s) for s in X_test_t.reset_index(drop = True)]\n",
    "\n",
    "Y_train = Y_train.reset_index(drop = True)\n",
    "Y_test = Y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_vector(tokens_list, word_model, predef_vocab, tfidf_matr = None, i = None):\n",
    "    s_t = np.zeros((1, word_model.vector_size))\n",
    "    if tfidf_matr is None:\n",
    "        for j in range(len(tokens_list)):\n",
    "            try:\n",
    "                s_t += word_model[tokens_list[j]]\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "    else:\n",
    "        for j in range(len(tokens_list)):\n",
    "            try:\n",
    "                tt = tokens_list[j]\n",
    "                tq = tfidf_matr[i, predef_vocab.index(tt)]\n",
    "                s_t += word_model[tt] * tq\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "    return s_t\n",
    "\n",
    "\n",
    "def get_corpus_matrix(corpus, word_model, predef_vocab, weights = False):\n",
    "    corpus_len = len(corpus)\n",
    "    sparse_matr = np.empty((corpus_len, word_model.vector_size))\n",
    "    tfidf_matr = None if not weights else TfidfVectorizer(vocabulary = predef_vocab).fit_transform(\n",
    "        [' '.join(e) for e in corpus])\n",
    "    for i in range(corpus_len):\n",
    "        sparse_matr[i] = get_token_vector(corpus[i], word_model, predef_vocab, tfidf_matr, i)\n",
    "        if not i%1000: print(i)\n",
    "    return sparse_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_report(y_test, y_prediction):\n",
    "    confusion_matr = confusion_matrix(y_test, y_prediction)\n",
    "    print(\"CONFUSION MATRIX:\\n{matr}\".format(matr=confusion_matr))\n",
    "    accuracy_of_model = accuracy_score(y_test, y_prediction)\n",
    "    print(\"ACCURACY:\\n{acc}\".format(acc = accuracy_of_model))\n",
    "    sklearn_report = classification_report(y_test, y_prediction)\n",
    "    print(\"TABLE:\\n{tab}\".format(tab=sklearn_report))\n",
    "    return (confusion_matr, accuracy_of_model, sklearn_report)\n",
    "\n",
    "\n",
    "def quick_init_and_train_word_cls_model_no_args(\n",
    "    x_train_t, x_test_t, y_train, y_test, word_model, predef_vocab, cls_model, weightened = False):\n",
    "    print('DATA PREPARATION START')\n",
    "    x_train = get_corpus_matrix(\n",
    "        x_train_t, word_model, predef_vocab, weightened\n",
    "    )\n",
    "    x_test = get_corpus_matrix(\n",
    "        x_test_t, word_model, predef_vocab, weightened\n",
    "    )\n",
    "    print('MODEL TRAINING START')\n",
    "    cls_m = cls_model()\n",
    "    cls_m.fit(x_train, y_train)\n",
    "    \n",
    "    y_prediction = cls_m.predict(x_test)\n",
    "    results = basic_report(y_test, y_prediction)\n",
    "    \n",
    "    return (cls_m, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
      "DATA PREPARATION START\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17734    17]\n",
      " [  602   397]]\n",
      "ACCURACY:\n",
      "0.9669866666666667\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17751\n",
      "           1       0.96      0.40      0.56       999\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.96      0.70      0.77     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this time we're using rf model on our sets, because of larger amounts of it \n",
    "# include classifier: RF\n",
    "print(type(model_w2v_vectors))\n",
    "random_forest_cls_dat_1 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, cleaned_vocab, RandomForestClassifier, False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second part of the task is: \n",
    "\n",
    "1. While performing a step 2 for text vectorization, for each word add its vector with tf-idf weight -> weighted average. \n",
    "2. Perform a same text classification task as it was required above. \n",
    "3. Calculate the metrics, compare with a vectorization approach without weightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17738    13]\n",
      " [  598   401]]\n",
      "ACCURACY:\n",
      "0.9674133333333333\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17751\n",
      "           1       0.97      0.40      0.57       999\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.97      0.70      0.78     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_2 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITHOUT weightning. \n",
    "2. Train text classification model.\n",
    "3. Calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "CONFUSION MATRIX:\n",
      "[[17738    13]\n",
      " [  668   331]]\n",
      "ACCURACY:\n",
      "0.96368\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     17751\n",
      "           1       0.96      0.33      0.49       999\n",
      "\n",
      "    accuracy                           0.96     18750\n",
      "   macro avg       0.96      0.67      0.74     18750\n",
      "weighted avg       0.96      0.96      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_3 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, cleaned_vocab, RandomForestClassifier\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITH tf-idf weightning. \n",
    "2. Train a text classification model. \n",
    "3. Calculate the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
	  "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17742     9]\n",
      " [  650   349]]\n",
      "ACCURACY:\n",
      "0.9648533333333333\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     17751\n",
      "           1       0.97      0.35      0.51       999\n",
      "\n",
      "    accuracy                           0.96     18750\n",
      "   macro avg       0.97      0.67      0.75     18750\n",
      "weighted avg       0.97      0.96      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_4 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dimentionality reduction methods such as t-SNE or PCA to make your 300 dim vectors available for 2D plotting. \n",
    "\n",
    "Select top (10-20) words for each cathegory BY TF-IDF SCORE, not counts!!! \n",
    "\n",
    "Plot on the ONE plot all of this words but colors must be different for top-words for obscene cathegory, clean, toxic, etc... \n",
    "\n",
    "See, if words from one cathegory are closer to each other than to others. \n",
    "Or you observe ~2 clusters: all of the toxic words, clean words.  \n",
    "Explain what you see and why. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as always, using PCA\n",
    "model_pca = PCA(n_components = 5)\n",
    "\n",
    "transformer = TfidfVectorizer(vocabulary = cleaned_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and, as usual, a lot of mess\n",
    "text_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cleaned']\n",
    "\n",
    "temp = df[text_categories[-1]]\n",
    "\n",
    "fast_concat = lambda ls: [' '.join(e) for e in ls]\n",
    "g = lambda l: [literal_eval(s) for s in l]\n",
    "\n",
    "texts_neutral = fast_concat(g(temp[~df[text_categories[:-1]].any(axis = 'columns')]))\n",
    "texts_toxic = fast_concat(g(temp[df.toxic != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_concat = fast_concat(g(df.cleaned))\n",
    "tf_idf_full = transformer.fit_transform(df_cleaned_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filter = np.zeros(len(cleaned_vocab))\n",
    "M = len(df_cleaned_concat)\n",
    "p_lim = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional part: \n",
    "\n",
    "1. Find a pre-trained FastText vectors, understand it's difference from W2V vectors. \n",
    "2. Vectorize all of your texts using FT model, perform a text classification, calculate the metrics, compare with W2V approach. \n",
    "\n",
    "Or/And you can:\n",
    "\n",
    "1. Train your own FT model and make the same. \n",
    "2. Compare it with previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.24 GiB for an array with shape (2000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-f5898f877dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     window=5)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, sg, hs, size, alpha, window, min_count, max_vocab_size, word_ngrams, sample, seed, workers, min_alpha, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, min_n, max_n, sorted_vocab, bucket, trim_rule, batch_words, callbacks, compatible_hash)\u001b[0m\n\u001b[0;32m    593\u001b[0m             sorted_vocab=bool(sorted_vocab), null_word=null_word, ns_exponent=ns_exponent)\n\u001b[0;32m    594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastTextTrainables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashfxn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[1;34m(self, hs, negative, wv, update, vocabulary)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprepare_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFastTextTrainables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_ngrams_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_ngrams_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36minit_ngrams_weights\u001b[1;34m(self, wv, update, vocabulary)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \"\"\"\n\u001b[0;32m   1149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m             \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_ngrams_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_vocab_lockf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_vocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_ngrams_lockf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_ngrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36minit_ngrams_weights\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m   2217\u001b[0m         \u001b[1;31m#    time because the vocab is not initialized at that stage.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2218\u001b[0m         \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2219\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngrams_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_ngrams_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_vocab_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.24 GiB for an array with shape (2000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "model_ft = FastText(sentences=df_sample_cleaned_list, \n",
    "                    size=300,\n",
    "                    min_count=5,\n",
    "                    window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_ft.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_ft.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cls_dat_5 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_ft, cleaned_vocab, RandomForestClassifier, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cls_dat_6 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_ft, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# saving models into c binary files, measures into dataframe\n",
    "def save_model_and_get_fancy_stats(cls_dat, cls_name):\n",
    "    dump(cls_dat[0], os.getcwd() + os.sep + cls_name + '.joblib')\n",
    "    cls_measures = list(map(float, cls_dat[1][2][70:100].split()))\n",
    "    # horrifying :D \n",
    "    return pd.Series({\n",
    "        'tp': cls_dat[1][0][0][0],\n",
    "        'tn': cls_dat[1][0][1][1],\n",
    "        'fn': cls_dat[1][0][1][0],\n",
    "        'fp': cls_dat[1][0][0][1],\n",
    "        'pre': cls_measures[0],\n",
    "        'rec': cls_measures[1],\n",
    "        'f1': cls_measures[2],\n",
    "        'acc': cls_dat[1][1]\n",
    "    }, name = cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(columns=['tp', 'tn', 'fp', 'fn', 'pre', 'rec', 'f1', 'acc'])\n",
    "#df_stats.set_index('model', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_1, 'rf_w2v_trained'))\n",
    "df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_2, 'rf_w2v_trained_tfidf'))\n",
    "df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_3, 'rf_w2v_pretrained'))\n",
    "df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_4, 'rf_w2v_pretrained_tfidf'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_5, 'rf_ft_trained'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_6, 'rf_ft_trained_tfidf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf_w2v_trained</th>\n",
       "      <td>17734.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.966987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_w2v_trained_tfidf</th>\n",
       "      <td>17738.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.967413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_w2v_pretrained</th>\n",
       "      <td>17738.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.963680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_w2v_pretrained_tfidf</th>\n",
       "      <td>17742.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.964853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tp     tn    fp     fn   pre  rec    f1  \\\n",
       "rf_w2v_trained           17734.0  397.0  17.0  602.0  0.97  1.0  0.98   \n",
       "rf_w2v_trained_tfidf     17738.0  401.0  13.0  598.0  0.97  1.0  0.98   \n",
       "rf_w2v_pretrained        17738.0  331.0  13.0  668.0  0.96  1.0  0.98   \n",
       "rf_w2v_pretrained_tfidf  17742.0  349.0   9.0  650.0  0.96  1.0  0.98   \n",
       "\n",
       "                              acc  \n",
       "rf_w2v_trained           0.966987  \n",
       "rf_w2v_trained_tfidf     0.967413  \n",
       "rf_w2v_pretrained        0.963680  \n",
       "rf_w2v_pretrained_tfidf  0.964853  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(os.getcwd() + os.sep + 'models_t4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "\n",
    "Please, provide a clear table or dataframe with all of the metrics for all of the trained/used models available.   \n",
    "\n",
    "Compare them to each other.   \n",
    "\n",
    "Make conclusions which one from your models worked better for this particular task.   \n",
    "BE CAREFUL: Having a better model performance on this particular task does not matter that this model is better than others in GENERAL. You need to make your own conclusions about this particular model applied to this particular task. Please, think and understand WHY.   \n",
    "Write your thoughts down below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поставленої задачі бінарної класифікаціх даних визначено, що непогані результати показала модель з використанням алгоритму Random Forest та набору навантажених tf-idf показниками текстових векторів, що були отримані з натренованої на наших даних моделі Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дійсно, хибно вважати що модель, яка проявила себе добре на одній задачі, буде давати добрі результати для інших.\n",
    "Використані моделі у цьому завданні призначені для семантичного аналізу текстів.\n",
    "Кілька слів про обрану модель в якості найкращої для задачі бінарної класифікації. Основними компонентами, що сприяли цьому, є наступні: навантаження векторизованих слів значеннями tf-idf (показник значущості слова дає змогу покращити роботу в цілому),\n",
    "інструмент Word2Vec та дані, які були використані для тренування моделі та формування векторних представлень слів."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
