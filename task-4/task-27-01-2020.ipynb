{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokenizer, lemmatizer, stop_words, punctuation, text): \n",
    "    tokens = tokenizer(text.lower())\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return [token for token in lemmas if token not in stop_words and token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_load = True\n",
    "\n",
    "if not bool_load:\n",
    "    df['cleaned'] = df.comment_text.apply(lambda x: preprocess_text(word_tokenize, lemmatizer, stop_words, punctuation, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save = False\n",
    "\n",
    "if bool_save:\n",
    "    df.to_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55225</th>\n",
       "      <td>93803cd626d36c85</td>\n",
       "      <td>Gasp, why did you revert the article in Ben 10...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[gasp, revert, article, ben, 10, gayneright, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123818</th>\n",
       "      <td>965304f2d10ace42</td>\n",
       "      <td>Why don't you give wikipedia a rest?173.160.22...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[n't, give, wikipedia, rest, 173.160.221.193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119173</th>\n",
       "      <td>7d184eceb1c98732</td>\n",
       "      <td>narc\\n\\nPlease quit fucking up my edits on Ste...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[narc, please, quit, fucking, edits, steak, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147033</th>\n",
       "      <td>35c9ae060bfcec5e</td>\n",
       "      <td>I'm sorry, but you have a history of taking th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['m, sorry, history, taking, counter, position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145811</th>\n",
       "      <td>228b5e325becebeb</td>\n",
       "      <td>\"\\n I don't believe that's true.  Notability a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[``, n't, believe, 's, true, notability, sourc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "55225   93803cd626d36c85  Gasp, why did you revert the article in Ben 10...   \n",
       "123818  965304f2d10ace42  Why don't you give wikipedia a rest?173.160.22...   \n",
       "119173  7d184eceb1c98732  narc\\n\\nPlease quit fucking up my edits on Ste...   \n",
       "147033  35c9ae060bfcec5e  I'm sorry, but you have a history of taking th...   \n",
       "145811  228b5e325becebeb  \"\\n I don't believe that's true.  Notability a...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "55225       0             0        0       0       0              0   \n",
       "123818      0             0        0       0       0              0   \n",
       "119173      1             0        1       0       0              0   \n",
       "147033      0             0        0       0       0              0   \n",
       "145811      0             0        0       0       0              0   \n",
       "\n",
       "                                                  cleaned  \n",
       "55225   [gasp, revert, article, ben, 10, gayneright, w...  \n",
       "123818      [n't, give, wikipedia, rest, 173.160.221.193]  \n",
       "119173  [narc, please, quit, fucking, edits, steak, di...  \n",
       "147033  ['m, sorry, history, taking, counter, position...  \n",
       "145811  [``, n't, believe, 's, true, notability, sourc...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our first model based on the vocabulary from df_sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With initialization model trained for 5 epochs \n",
    "\n",
    "model = Word2Vec(sentences=df_sample.cleaned.tolist(), \n",
    "         size=100,      # embedding vector size\n",
    "         min_count=5,   # consider words that occured at least 5 times\n",
    "         window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99183858, 117446610)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training the model \n",
    "\n",
    "model.train(sentences=df_sample.cleaned.tolist(), \n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=30\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab # to look at vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.6032766103744507),\n",
       " ('thing', 0.5934039354324341),\n",
       " ('person', 0.5462353229522705),\n",
       " ('everyone', 0.5449029207229614),\n",
       " ('editor', 0.5396105647087097),\n",
       " ('really', 0.5300643444061279),\n",
       " ('way', 0.5156518220901489),\n",
       " ('admins', 0.5011159181594849),\n",
       " ('guy', 0.48877382278442383),\n",
       " ('personally', 0.4884004294872284)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next approach is to try to use the already pretrained model, which can be downloaded from here:\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "model:   \n",
    "GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\n",
    "    os.getcwd() + os.sep + \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to use GloVe model too and experiment with it: <- later\n",
    "# import gensim.downloader as api\n",
    "# model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Cosine similarity\n",
    "\n",
    "To measure how similar two words are, we need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows: \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "where $u.v$ is the dot product (or inner product) of two vectors, $||u||_2$ is the norm (or length) of the vector $u$, and $\\theta$ is the angle between $u$ and $v$. This similarity depends on the angle between $u$ and $v$. If $u$ and $v$ are very similar, their cosine similarity will be close to 1; if they are dissimilar, the cosine similarity will take a smaller value. \n",
    "\n",
    "<img src=\"cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **Figure 1**: The cosine of the angle between two vectors is a measure of how similar they are</center></caption>\n",
    "\n",
    "**Exercise**: Implement the function `cosine_similarity()` to evaluate similarity between word vectors.\n",
    "\n",
    "**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(w1, w2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between w1 and w2\n",
    "    \n",
    "    Arguments:\n",
    "        w1 : word vector        \n",
    "        w2 : word vector \n",
    "    Returns:\n",
    "        cosine_similarity \n",
    "    \"\"\"\n",
    "    if (not np.any(w1) or not np.any(w2)): # check input is not zero-vector\n",
    "        return 0\n",
    "    \n",
    "    # Dot product between w1 and w2\n",
    "    dot = np.dot(w1, w2)\n",
    "    # L2 norm of w1\n",
    "    norm_u = np.linalg.norm(w1) \n",
    "    # L2 norm of w2 \n",
    "    norm_v = np.linalg.norm(w2) \n",
    "    # Cosine similarity \n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "father = model.get_vector(\"father\")\n",
    "mother = model.get_vector(\"mother\")\n",
    "\n",
    "ball = model.get_vector(\"ball\")\n",
    "crocodile = model.get_vector(\"crocodile\")\n",
    "\n",
    "france = model.get_vector(\"france\")\n",
    "paris = model.get_vector(\"paris\")\n",
    "italy = model.get_vector(\"italy\")\n",
    "rome = model.get_vector(\"rome\")\n",
    "\n",
    "kiev = model.get_vector(\"kiev\")\n",
    "ukraine = model.get_vector(\"ukraine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.79014826\n",
      "cosine_similarity(ball, crocodile) =  0.10283584\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.1988747\n",
      "cosine_similarity(kiev, ukraine) =  0.3738725\n"
     ]
    }
   ],
   "source": [
    "fast_print = lambda u, v, tag1, tag2: print(\n",
    "    \"cosine_similarity({t1}, {t2}) = \".format(t1 = tag1, t2 = tag2), cosine_similarity(u, v)\n",
    ")\n",
    "\n",
    "fast_print(father, mother, \"father\", \"mother\")\n",
    "fast_print(ball, crocodile, \"ball\", \"crocodile\")\n",
    "fast_print(france - paris, rome - italy, \"france - paris\", \"rome - italy\")\n",
    "fast_print(kiev, ukraine, \"kiev\", \"ukraine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approximate expected output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.79014826\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(ball, crocodile)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.10283585\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.421037\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Word analogy task\n",
    "\n",
    "In the word analogy task, we complete the sentence <font color='brown'>\"*a* is to *b* as *c* is to **____**\"</font>. An example is <font color='brown'> '*man* is to *woman* as *king* is to *queen*' </font>. In detail, we are trying to find a word *d*, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \\approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity. \n",
    "\n",
    "**Exercise**: Complete the code below to be able to perform word analogies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note***: here you will need to complete a function in the sections, which are marked as:\n",
    "\n",
    "```\n",
    "# ----- Start ----- #\n",
    "Your code should be written in-between the lines\n",
    "# ------ End ------ #\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_analogy(word_1, word_2, word_3, model):\n",
    "    \"\"\"\n",
    "    Finds the word to complete analogy (see explanation above): a is to b as c is to ____. \n",
    "    \n",
    "    Arguments:\n",
    "    word_1 -- a word, string\n",
    "    word_2 -- a word, string\n",
    "    word_3 -- a word, string\n",
    "    model -- word embeddings model \n",
    "    \n",
    "    Returns:\n",
    "    best_word --  the word such that v_1 - v_2 is close to v_best_word - v_3, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    # convert words to lower case\n",
    "    word_1, word_2, word_3 = word_1.lower(), word_2.lower(), word_3.lower()\n",
    "    \n",
    "    # ----- Start ----- #\n",
    "    # Get the word embeddings v_a, v_b and v_c (≈1-3 lines)\n",
    "    fast_get = lambda word: model.get_vector(word)\n",
    "    e_1, e_2, e_3 = tuple(map(fast_get, [word_1, word_2, word_3]))\n",
    "    # ------ End ------ #\n",
    "    \n",
    "    words = list(model.vocab.keys())\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None\n",
    "\n",
    "    # Loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        e_j = fast_get(w)\n",
    "        # to avoid best_word being one of the input words, skip them and continue iteration.\n",
    "        if w in [word_1, word_2, word_3]:\n",
    "            continue\n",
    "        \n",
    "        # ----- Start ----- #\n",
    "        # Compute cosine similarity between the vector (e_2 - e_1) and the vector ((w's vector) - e_3)\n",
    "        cosine_sim = cosine_similarity(e_2 - e_1, e_j - e_3)\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "        # do not forget to set new max_cosine_sim to the current value and best_word as well\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        # ------ End ------ #\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: king -> queen\n",
      "bad -> good :: sad -> wonderful\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [\n",
    "    ('man', 'woman', 'king'), \n",
    "    ('bad', 'good', 'sad'), \n",
    "    ('man', 'woman', 'boy'), \n",
    "    ('small', 'smaller', 'large')\n",
    "]\n",
    "\n",
    "for triad in triads_to_try:\n",
    "    print('{} -> {} :: {} -> {}'.format( *triad, find_word_analogy(*triad, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **man -> woman** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         king -> queen\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **bad -> good** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         sad -> wonderful\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next part of the task is to:  \n",
    "\n",
    "1. Train your own W2V model using the proposed method above. Use all of the tokens created after your preprocessing pipeline in the previous tasks. (deleting stop_words, punctuation, lowercasing, etc - play as you want).  \n",
    "2. Use obtained vectors to obtain text vectors using such pipeline: \n",
    "  1. For each word in a preprocessed text, get a word vector from the W2V model. \n",
    "  2. Add them together to obtain vectors for texts (sum them together, or get mean vector) \n",
    "3. Use obtained text vectors as a text representation to perform a text classification task.  \n",
    "   Proposed - use binary classification (for example: select only 'obscene' text and clean and try to distinguish them one from another)\n",
    "4. Calculate the metrics - TP, FP, FN, TN, precision, recall, F1 score, F2 score, accurary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=df_sample.cleaned.tolist(), \n",
    "         size=100,      # embedding vector size\n",
    "         min_count=5,   # consider words that occured at least 5 times\n",
    "         window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second part of the task is: \n",
    "\n",
    "1. While performing a step 2 for text vectorization, for each word add its vector with tf-idf weight -> weighted average. \n",
    "2. Perform a same text classification task as it was required above. \n",
    "3. Calculate the metrics, compare with a vectorization approach without weightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITHOUT weightning. \n",
    "2. Train text classification model.\n",
    "3. Calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITH tf-idf weightning. \n",
    "2. Train a text classification model. \n",
    "3. Calculate the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dimentionality reduction methods such as t-SNE or PCA to make your 300 dim vectors available for 2D plotting. \n",
    "\n",
    "Select top (10-20) words for each cathegory BY TF-IDF SCORE, not counts!!! \n",
    "\n",
    "Plot on the ONE plot all of this words but colors must be different for top-words for obscene cathegory, clean, toxic, etc... \n",
    "\n",
    "See, if words from one cathegory are closer to each other than to others. \n",
    "Or you observe ~2 clusters: all of the toxic words, clean words.  \n",
    "Explain what you see and why. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional part: \n",
    "\n",
    "1. Find a pre-trained FastText vetors, understand it's difference from W2V vectors. \n",
    "2. Vectorize all of your texts using FT model, perform a text classification, calculate the metrics, compare with W2V approach. \n",
    "\n",
    "Or/And you can:\n",
    "\n",
    "1. Train your own FT model and make the same. \n",
    "2. Compare it with previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "\n",
    "Please, provide a clear table or dataframe with all of the metrics for all of the trained/used models available.   \n",
    "\n",
    "Compare them to each other.   \n",
    "\n",
    "Make conclusions which one from your models worked better for this particular task.   \n",
    "BE CAREFUL: Having a better model performance on this particular task does not matter that this model is better than others in GENERAL. You need to make your own conclusions about this particular model applied to this particular task. Please, think and understand WHY.   \n",
    "Write your thoughts down below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your conclusions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your thoughts about the last question here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
